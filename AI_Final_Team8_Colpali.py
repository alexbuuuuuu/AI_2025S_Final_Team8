import os
import json
import argparse
import openai
import faiss
import numpy as np
from typing import List, Dict, Any, Union
from datetime import datetime
import tiktoken
import glob
import re
import torch
import pandas as pd
from pdf2image import convert_from_path
from PIL import Image
from tqdm import tqdm
from pathlib import Path

# ----------------------------
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans

# ColPali imports
from colpali_engine.models import ColPali
from colpali_engine.models.paligemma.colpali.processing_colpali import ColPaliProcessor
from colpali_engine.utils.torch_utils import ListDataset, get_torch_device
from torch.utils.data import DataLoader
from typing import cast

# ----------------------------
# AI_2025S_Team 8_Colpali Version
# System Main Code & Extension implementation by D13944024, è”¡å®œæ·€
# Modifying by D13949002, é‚±ç¿Š

# é…ç½® OpenAI API Key
openai.api_key = os.getenv("OPENAI_API_KEY")

# åµŒå…¥æ¨¡å‹èˆ‡ç¶­åº¦
EMBEDDING_MODEL = "text-embedding-ada-002"
EMBEDDING_DIM = 1536
MAX_TOKENS = 7000
CHUNK_SIZE = 5000
CHUNK_OVERLAP = 500

# ColPali è¨­å®š
COLPALI_MODEL_NAME = "vidore/colpali-v1.2"

# ========= 1. ColPali åœ–ç‰‡è™•ç†é¡åˆ¥ =========

class ColPaliImageProcessor:
    def __init__(self, model_name: str = COLPALI_MODEL_NAME):
        """åˆå§‹åŒ– ColPali åœ–ç‰‡è™•ç†å™¨"""
        self.device = get_torch_device("cuda" if torch.cuda.is_available() else "cpu")
        self.model_name = model_name
        self.model = None
        self.processor = None
        self.ocr_engine = None
        self.ocr_type = None
        self._load_model()
        self._init_ocr()
        
    def _load_model(self):
        """è¼‰å…¥ ColPali æ¨¡å‹"""
        print(f"è¼‰å…¥ ColPali æ¨¡å‹: {self.model_name}")
        try:
            self.model = ColPali.from_pretrained(
                self.model_name,
                torch_dtype=torch.bfloat16,
                device_map=self.device,
            ).eval()
            self.processor = cast(ColPaliProcessor, ColPaliProcessor.from_pretrained(self.model_name))
            print("âœ… ColPali æ¨¡å‹è¼‰å…¥å®Œæˆ")
        except Exception as e:
            print(f"âŒ è¼‰å…¥ ColPali æ¨¡å‹å¤±æ•—: {e}")
            raise
    
    def _init_ocr(self):
        """åˆå§‹åŒ– OCR å¼•æ“ï¼ˆæŒ‰å„ªå…ˆé †åºå˜—è©¦ï¼‰"""
        # å˜—è©¦è¼‰å…¥ä¸åŒçš„ OCR å¼•æ“ï¼ŒæŒ‰å„ªå…ˆé †åº
        ocr_engines = [
            ("PaddleOCR", self._init_paddleocr),
            ("EasyOCR", self._init_easyocr),
            ("Tesseract", self._init_tesseract)
        ]
        
        for engine_name, init_func in ocr_engines:
            try:
                init_func()
                print(f"âœ… {engine_name} OCR å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
                # ç¢ºä¿ ocr_type è¢«è¨­å®š
                if self.ocr_type is None:
                    self.ocr_type = engine_name
                return
            except Exception as e:
                print(f"âš ï¸  {engine_name} åˆå§‹åŒ–å¤±æ•—: {e}")
                continue
        
        print("âŒ æ‰€æœ‰ OCR å¼•æ“åˆå§‹åŒ–å¤±æ•—")
        self.ocr_engine = None
        self.ocr_type = None

    

    def _init_paddleocr(self):
        """åˆå§‹åŒ– PaddleOCR"""
        from paddleocr import PaddleOCR
        self.ocr_engine = PaddleOCR(
            use_angle_cls=True,
            lang='ch',  # æ”¯æ´ä¸­æ–‡
            show_log=False,
            use_gpu=False
        )
        self.ocr_type = "PaddleOCR"
    
    def _init_easyocr(self):
        """åˆå§‹åŒ– EasyOCRï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        import easyocr
        try:
            # ä½¿ç”¨æ›´å¥½çš„èªè¨€çµ„åˆå’Œè¨­å®š
            self.ocr_engine = easyocr.Reader(
                ['ch_tra', 'en'],  # ç¹é«”ä¸­æ–‡ + è‹±æ–‡
                gpu=False,
                verbose=False,
                model_storage_directory=None,  # ä½¿ç”¨é è¨­æ¨¡å‹è·¯å¾‘
                download_enabled=True
            )
            self.ocr_type = "EasyOCR"
            print("âœ… EasyOCR åˆå§‹åŒ–æˆåŠŸ (ç¹é«”ä¸­æ–‡+è‹±æ–‡)")
        except Exception as e:
            print(f"âš ï¸  ç¹é«”ä¸­æ–‡æ¨¡å¼å¤±æ•—: {e}")
            try:
                # é™ç´šåˆ°ç°¡é«”ä¸­æ–‡
                self.ocr_engine = easyocr.Reader(['ch_sim', 'en'], gpu=False, verbose=False)
                self.ocr_type = "EasyOCR"
                print("âœ… EasyOCR åˆå§‹åŒ–æˆåŠŸ (ç°¡é«”ä¸­æ–‡+è‹±æ–‡)")
            except Exception as e2:
                # æœ€å¾Œé™ç´šåˆ°ç´”è‹±æ–‡
                self.ocr_engine = easyocr.Reader(['en'], gpu=False, verbose=False)
                self.ocr_type = "EasyOCR"
                print("âœ… EasyOCR åˆå§‹åŒ–æˆåŠŸ (ç´”è‹±æ–‡)")

    
    def _init_tesseract(self):
        """åˆå§‹åŒ– Tesseract"""
        import pytesseract
        # æ¸¬è©¦æ˜¯å¦å¯ç”¨
        pytesseract.get_tesseract_version()
        self.ocr_engine = pytesseract
        self.ocr_type = "Tesseract"
    
    def extract_text_from_image(self, image_path: str, queries: List[str] = None) -> str:
        """å¾åœ–ç‰‡ä¸­æå–æ–‡å­—å…§å®¹"""
        try:
            print(f"ğŸ” é–‹å§‹è™•ç†åœ–ç‰‡: {image_path}")
            
            # è¼‰å…¥åœ–ç‰‡
            if isinstance(image_path, str):
                image = Image.open(image_path)
                print(f"ğŸ“· åœ–ç‰‡å°ºå¯¸: {image.size}")
            else:
                image = image_path
                image_path = "temp_image"  # è‡¨æ™‚åç¨±
            
            # 1. ä½¿ç”¨ ColPali é€²è¡Œæ–‡ä»¶ç†è§£å’Œæª¢ç´¢
            print("ğŸ§  ä½¿ç”¨ ColPali é€²è¡Œæ–‡ä»¶ç†è§£...")
            colpali_confidence = self._analyze_with_colpali(image, queries)
            
            # 2. ä½¿ç”¨ OCR é€²è¡Œæ–‡å­—æå–
            if self.ocr_engine:
                print(f"ğŸ”¤ ä½¿ç”¨ {self.ocr_type} é€²è¡Œæ–‡å­—æå–...")
                extracted_text = self._extract_with_ocr(image_path, image)
            else:
                print("âš ï¸  æ²’æœ‰å¯ç”¨çš„ OCR å¼•æ“ï¼Œå˜—è©¦ä½¿ç”¨å‚™ç”¨æ–¹æ³•...")
                extracted_text = self._fallback_text_extraction(image_path)
            
            if extracted_text and len(extracted_text.strip()) > 0:
                print(f"âœ… æˆåŠŸæå–æ–‡å­—å…§å®¹ ({len(extracted_text)} å­—å…ƒ)")
                print("ğŸ“ æå–çš„æ–‡å­—å…§å®¹:")
                print("-" * 50)
                print(extracted_text)
                print("-" * 50)
                
                # 3. çµåˆ ColPali çš„ç†è§£å’Œ OCR çš„æ–‡å­—æå–
                enhanced_text = self._enhance_text_with_colpali(extracted_text, colpali_confidence)
                
                return enhanced_text
            else:
                raise ValueError("ç„¡æ³•å¾åœ–ç‰‡ä¸­æå–æ–‡å­—å…§å®¹")
                
        except Exception as e:
            print(f"âŒ åœ–ç‰‡æ–‡å­—æå–å¤±æ•—: {e}")
            raise ValueError(f"åœ–ç‰‡è™•ç†å¤±æ•—: {e}")
    
    def _analyze_with_colpali(self, image: Image.Image, queries: List[str] = None) -> Dict:
        """ä½¿ç”¨ ColPali åˆ†æåœ–ç‰‡"""
        try:
            if queries is None:
                queries = [
                    "é€™æ˜¯ä»€éº¼é¡å‹çš„å»£å‘Šï¼Ÿ",
                    "åœ–ç‰‡ä¸­æœ‰ä»€éº¼ç”¢å“ä¿¡æ¯ï¼Ÿ",
                    "æœ‰ä»€éº¼å¥åº·æˆ–ç¾å®¹è²æ˜ï¼Ÿ",
                    "åœ–ç‰‡çš„ä¸»è¦å…§å®¹æ˜¯ä»€éº¼ï¼Ÿ",
                    "é€™å€‹å»£å‘Šåœ¨å®£å‚³ä»€éº¼åŠŸæ•ˆï¼Ÿ"
                ]
            
            print(f"ğŸ”¤ ä½¿ç”¨ {len(queries)} å€‹æŸ¥è©¢ä¾†åˆ†ææ–‡ä»¶...")
            
            # è™•ç†æŸ¥è©¢
            query_loader = DataLoader(
                dataset=ListDataset[str](queries),
                batch_size=1,
                shuffle=False,
                collate_fn=lambda x: self.processor.process_queries(x),
            )
            
            # ç”ŸæˆæŸ¥è©¢åµŒå…¥
            query_embeddings = []
            for batch_query in query_loader:
                with torch.no_grad():
                    batch_query = {k: v.to(self.model.device) for k, v in batch_query.items()}
                    embeddings_query = self.model(**batch_query)
                query_embeddings.extend(list(torch.unbind(embeddings_query.to("cpu"))))
            
            # è™•ç†åœ–ç‰‡
            image_loader = DataLoader(
                dataset=ListDataset[Image.Image]([image]),
                batch_size=1,
                shuffle=False,
                collate_fn=lambda x: self.processor.process_images(x),
            )
            
            # ç”Ÿæˆåœ–ç‰‡åµŒå…¥
            image_embeddings = []
            for batch_doc in image_loader:
                with torch.no_grad():
                    batch_doc = {k: v.to(self.model.device) for k, v in batch_doc.items()}
                    embeddings_doc = self.model(**batch_doc)
                image_embeddings.extend(list(torch.unbind(embeddings_doc.to("cpu"))))
            
            # è¨ˆç®—ç›¸ä¼¼åº¦
            scores = []
            best_score = 0
            for query_emb in query_embeddings:
                for img_emb in image_embeddings:
                    score = torch.einsum("bd,cd->bc", query_emb, img_emb).max()
                    score_value = score.item()
                    scores.append(score_value)
                    best_score = max(best_score, score_value)
            
            print(f"ğŸ“Š ColPali åˆ†æå®Œæˆï¼Œæœ€é«˜ç›¸ä¼¼åº¦åˆ†æ•¸: {best_score:.4f}")
            
            return {
                "confidence": best_score,
                "document_type": "advertisement",
                "has_text": True,
                "scores": scores
            }
            
        except Exception as e:
            print(f"âš ï¸  ColPali åˆ†æå¤±æ•—: {e}")
            return {"confidence": 0.5, "document_type": "unknown", "has_text": True}
    
    def _preprocess_image(self, image_path: str) -> str:
        """åœ–ç‰‡é è™•ç†ä»¥æ”¹å–„ OCR æ•ˆæœ"""
        try:
            from PIL import Image, ImageEnhance, ImageFilter
            import cv2
            import numpy as np
            
            # è¼‰å…¥åœ–ç‰‡
            if isinstance(image_path, str):
                image = Image.open(image_path)
            else:
                image = image_path
            
            # è½‰æ›ç‚º OpenCV æ ¼å¼
            img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # 1. èª¿æ•´å¤§å°ï¼ˆå¦‚æœåœ–ç‰‡å¤ªå¤§ï¼‰
            height, width = img_cv.shape[:2]
            if width > 1500 or height > 1500:
                scale = min(1500/width, 1500/height)
                new_width = int(width * scale)
                new_height = int(height * scale)
                img_cv = cv2.resize(img_cv, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # 2. è½‰æ›ç‚ºç°åº¦
            gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
            
            # 3. é™å™ª
            denoised = cv2.fastNlMeansDenoising(gray)
            
            # 4. å¢å¼·å°æ¯”åº¦
            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
            enhanced = clahe.apply(denoised)
            
            # 5. äºŒå€¼åŒ–
            _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # å„²å­˜é è™•ç†å¾Œçš„åœ–ç‰‡
            processed_path = "temp_processed_image.png"
            cv2.imwrite(processed_path, binary)
            
            return processed_path
            
        except Exception as e:
            print(f"âš ï¸  åœ–ç‰‡é è™•ç†å¤±æ•—: {e}")
            return image_path  # è¿”å›åŸå§‹è·¯å¾‘

    
    def _extract_with_ocr(self, image_path: str, image: Image.Image = None) -> str:
        """ä½¿ç”¨ OCR æå–æ–‡å­—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        if not self.ocr_engine:
            raise ValueError("æ²’æœ‰å¯ç”¨çš„ OCR å¼•æ“")
        
        try:
            # åœ–ç‰‡é è™•ç†
            processed_path = self._preprocess_image(image_path)
            
            if self.ocr_type == "EasyOCR":
                # ä½¿ç”¨æ›´å¥½çš„åƒæ•¸è¨­å®š
                results = self.ocr_engine.readtext(
                    processed_path,
                    detail=1,  # è¿”å›è©³ç´°ä¿¡æ¯
                    paragraph=False,  # ä¸åˆä½µæ®µè½
                    width_ths=0.7,  # æ–‡å­—å¯¬åº¦é–¾å€¼
                    height_ths=0.7,  # æ–‡å­—é«˜åº¦é–¾å€¼
                    text_threshold=0.7,  # æ–‡å­—æª¢æ¸¬é–¾å€¼
                    link_threshold=0.4,  # æ–‡å­—é€£æ¥é–¾å€¼
                    low_text=0.4  # ä½æ–‡å­—åˆ†æ•¸é–¾å€¼
                )
                
                # éæ¿¾ä½ä¿¡å¿ƒåº¦çš„çµæœ
                filtered_results = [item for item in results if item[2] > 0.5]
                text_parts = [item[1] for item in filtered_results]
                final_text = '\n'.join(text_parts)
                
            elif self.ocr_type == "PaddleOCR":
                result = self.ocr_engine.ocr(processed_path, cls=True)
                if result[0] is None:
                    return "æœªæª¢æ¸¬åˆ°æ–‡å­—"
                
                # éæ¿¾ä½ä¿¡å¿ƒåº¦çš„çµæœ
                filtered_results = [line for line in result[0] if line[1][1] > 0.5]
                text_parts = [line[1][0] for line in filtered_results]
                final_text = '\n'.join(text_parts)
                
            elif self.ocr_type == "Tesseract":
                from PIL import Image
                img = Image.open(processed_path)
                final_text = pytesseract.image_to_string(
                    img, 
                    lang='chi_tra+eng',
                    config='--psm 6'  # çµ±ä¸€æ–‡å­—å¡Šæ¨¡å¼
                )
            
            # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
            if processed_path != image_path and os.path.exists(processed_path):
                os.remove(processed_path)
            
            return final_text.strip()
            
        except Exception as e:
            print(f"âŒ {self.ocr_type} æ–‡å­—æå–å¤±æ•—: {e}")
            raise

    
    def _enhance_text_with_colpali(self, ocr_text: str, colpali_info: Dict) -> str:
        """çµåˆ ColPali ç†è§£å¢å¼· OCR æ–‡å­—"""
        # æ ¹æ“š ColPali çš„ç†è§£ä¾†æ”¹å–„ OCR çµæœ
        enhanced_text = ocr_text
        
        # ç°¡å–®çš„æ–‡å­—æ¸…ç†
        lines = enhanced_text.split('\n')
        cleaned_lines = []
        
        for line in lines:
            line = line.strip()
            if len(line) > 1:  # éæ¿¾å¤ªçŸ­çš„è¡Œ
                cleaned_lines.append(line)
        
        enhanced_text = "\n".join(cleaned_lines)
        
        # æ ¹æ“š ColPali çš„ä¿¡å¿ƒåˆ†æ•¸æä¾›é¡å¤–ä¿¡æ¯
        confidence = colpali_info.get('confidence', 0)
        if confidence > 0.8:
            print(f"ğŸ¯ ColPali é«˜ä¿¡å¿ƒåˆ†æ•¸ ({confidence:.3f})ï¼Œæ–‡å­—æå–å“è³ªé€šé")
        elif confidence > 0.5:
            print(f"âš ï¸  ColPali ä¸­ç­‰ä¿¡å¿ƒåˆ†æ•¸ ({confidence:.3f})ï¼Œå»ºè­°æª¢æŸ¥æ–‡å­—æå–çµæœ")
        else:
            print(f"âŒ ColPali ä½ä¿¡å¿ƒåˆ†æ•¸ ({confidence:.3f})ï¼Œæ–‡å­—æå–å¯èƒ½ä¸å®Œæ•´")
        
        return enhanced_text
    
    def _fallback_text_extraction(self, image_path: str) -> str:
        """å‚™ç”¨æ–‡å­—æå–æ–¹æ³•"""
        try:
            print("ğŸ”„ å˜—è©¦ä½¿ç”¨å‚™ç”¨æ–‡å­—æå–æ–¹æ³•...")
            
            # å˜—è©¦ä½¿ç”¨ pytesseract OCR
            try:
                import pytesseract
                if isinstance(image_path, str) and os.path.exists(image_path):
                    image = Image.open(image_path)
                else:
                    raise ValueError("ç„¡æ•ˆçš„åœ–ç‰‡è·¯å¾‘")
                
                text = pytesseract.image_to_string(image, lang='chi_tra+eng')
                if text and len(text.strip()) > 0:
                    print(f"âœ… å‚™ç”¨ OCR æå–æˆåŠŸ: {len(text)} å­—å…ƒ")
                    print("ğŸ“ å‚™ç”¨ OCR æå–çš„æ–‡å­—å…§å®¹:")
                    print("-" * 50)
                    print(text)
                    print("-" * 50)
                    return text
            except ImportError:
                print("âš ï¸  pytesseract æœªå®‰è£ï¼Œç„¡æ³•ä½¿ç”¨å‚™ç”¨ OCR æ–¹æ¡ˆ")
            except Exception as e:
                print(f"âš ï¸  å‚™ç”¨ OCR æå–å¤±æ•—: {e}")
            
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±æ•—ï¼Œè¿”å›éŒ¯èª¤ä¿¡æ¯
            error_msg = f"""
âŒ ç„¡æ³•å¾åœ–ç‰‡ {image_path} ä¸­æå–æ–‡å­—å…§å®¹ã€‚

ğŸ“‹ å»ºè­°è§£æ±ºæ–¹æ¡ˆï¼š
1. å®‰è£ PaddleOCRï¼ˆæ¨è–¦ï¼‰: pip install paddlepaddle paddleocr
2. å®‰è£ EasyOCR: pip install easyocr  
3. å®‰è£ Tesseract: pip install pytesseract
4. ç¢ºä¿åœ–ç‰‡è³ªé‡æ¸…æ™°ï¼Œæ–‡å­—å¯è®€
5. æ‰‹å‹•è¼¸å…¥æ–‡å­—å…§å®¹é€²è¡Œæª¢æ¸¬

ğŸ’¡ å®‰è£ä»»ä¸€ OCR å¥—ä»¶å¾Œé‡æ–°é‹è¡Œå³å¯ã€‚
"""
            print(error_msg)
            return ""
            
        except Exception as e:
            print(f"âŒ å‚™ç”¨æ–‡å­—æå–ä¹Ÿå¤±æ•—: {e}")
            return ""

# ========= å®‰è£æŒ‡å—å‡½æ•¸ =========

def print_ocr_installation_guide():
    """æ‰“å° OCR å®‰è£æŒ‡å—"""
    guide = """
ğŸ“¦ OCR å¥—ä»¶å®‰è£æŒ‡å—
==================

ğŸ¥‡ æ–¹æ¡ˆ 1ï¼šPaddleOCRï¼ˆæ¨è–¦ï¼Œä¸­æ–‡æ•ˆæœæœ€å¥½ï¼‰
pip install paddlepaddle paddleocr

ğŸ¥ˆ æ–¹æ¡ˆ 2ï¼šEasyOCRï¼ˆç°¡å–®æ˜“ç”¨ï¼Œæ”¯æ´å¤šèªè¨€ï¼‰
pip install easyocr

ğŸ¥‰ æ–¹æ¡ˆ 3ï¼šTesseractï¼ˆéœ€è¦é¡å¤–å®‰è£ç³»çµ±å¥—ä»¶ï¼‰

Ubuntu/Debian:
sudo apt-get install tesseract-ocr tesseract-ocr-chi-tra tesseract-ocr-chi-sim
pip install pytesseract

macOS:
brew install tesseract tesseract-lang
pip install pytesseract

Windows:
1. ä¸‹è¼‰ä¸¦å®‰è£ Tesseract: https://github.com/UB-Mannheim/tesseract/wiki
2. pip install pytesseract

âœ… å®‰è£ä»»ä¸€å¥—ä»¶å¾Œï¼Œç³»çµ±å°‡è‡ªå‹•ä½¿ç”¨è©² OCR å¼•æ“é€²è¡Œæ–‡å­—æå–ã€‚
"""
    print(guide)

# ========= æ¸¬è©¦å‡½æ•¸ =========

def test_colpali_with_sample():
    """æ¸¬è©¦ ColPali åŠŸèƒ½"""
    try:
        print("ğŸ§ª æ¸¬è©¦ ColPali åœ–ç‰‡è™•ç†åŠŸèƒ½...")
        processor = ColPaliImageProcessor()
        
        # å‰µå»ºä¸€å€‹æ¸¬è©¦åœ–ç‰‡ï¼ˆå¦‚æœæ²’æœ‰çœŸå¯¦åœ–ç‰‡ï¼‰
        from PIL import Image, ImageDraw, ImageFont
        
        # å‰µå»ºæ¸¬è©¦åœ–ç‰‡
        img = Image.new('RGB', (400, 200), color='white')
        draw = ImageDraw.Draw(img)
        
        # æ·»åŠ æ¸¬è©¦æ–‡å­—
        test_text = "æœ¬ç”¢å“èƒ½æœ‰æ•ˆæ”¹å–„é«”è³ª\nä¿ƒé€²æ–°é™³ä»£è¬\nå¥åº·ç¶­æŒ"
        try:
            # å˜—è©¦ä½¿ç”¨ç³»çµ±å­—é«”
            font = ImageFont.truetype("arial.ttf", 20)
        except:
            # å¦‚æœæ²’æœ‰å­—é«”ï¼Œä½¿ç”¨é è¨­å­—é«”
            font = ImageFont.load_default()
        
        draw.text((50, 50), test_text, fill='black', font=font)
        
        # å„²å­˜æ¸¬è©¦åœ–ç‰‡
        test_image_path = "test_advertisement.png"
        img.save(test_image_path)
        print(f"âœ… å‰µå»ºæ¸¬è©¦åœ–ç‰‡: {test_image_path}")
        
        # æ¸¬è©¦æ–‡å­—æå–
        extracted_text = processor.extract_text_from_image(test_image_path)
        print(f"ğŸ“ æå–çµæœ: {extracted_text}")
        
        # æ¸…ç†æ¸¬è©¦æª”æ¡ˆ
        os.remove(test_image_path)
        print("ğŸ§¹ æ¸…ç†æ¸¬è©¦æª”æ¡ˆå®Œæˆ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

# ========= 2. é€šç”¨å·¥å…·å‡½æ•¸ =========
def _extract_with_multiple_ocr(self, image_path: str, image: Image.Image = None) -> str:
    """ä½¿ç”¨å¤šå€‹ OCR å¼•æ“ä¸¦é¸æ“‡æœ€ä½³çµæœ"""
    results = []
    
    # 1. é è™•ç†åœ–ç‰‡
    processed_path = self._preprocess_image(image_path)
    
    # 2. å˜—è©¦ä¸åŒçš„ OCR å¼•æ“
    ocr_engines = []
    
    # EasyOCR
    try:
        import easyocr
        reader = easyocr.Reader(['ch_tra', 'en'], gpu=False, verbose=False)
        result = reader.readtext(processed_path)
        text = '\n'.join([item[1] for item in result if item[2] > 0.3])  # ä¿¡å¿ƒåº¦éæ¿¾
        results.append(('EasyOCR', text, len(text)))
        print(f"ğŸ“ EasyOCR çµæœ: {len(text)} å­—å…ƒ")
    except Exception as e:
        print(f"âš ï¸  EasyOCR å¤±æ•—: {e}")
    
    # PaddleOCR
    try:
        from paddleocr import PaddleOCR
        paddle_ocr = PaddleOCR(use_angle_cls=True, lang='ch', show_log=False)
        result = paddle_ocr.ocr(processed_path, cls=True)
        if result[0]:
            text = '\n'.join([line[1][0] for line in result[0] if line[1][1] > 0.3])
            results.append(('PaddleOCR', text, len(text)))
            print(f"ğŸ“ PaddleOCR çµæœ: {len(text)} å­—å…ƒ")
    except Exception as e:
        print(f"âš ï¸  PaddleOCR å¤±æ•—: {e}")
    
    # Tesseract
    try:
        import pytesseract
        from PIL import Image
        img = Image.open(processed_path)
        text = pytesseract.image_to_string(img, lang='chi_tra+eng')
        results.append(('Tesseract', text, len(text.strip())))
        print(f"ğŸ“ Tesseract çµæœ: {len(text.strip())} å­—å…ƒ")
    except Exception as e:
        print(f"âš ï¸  Tesseract å¤±æ•—: {e}")
    
    # æ¸…ç†è‡¨æ™‚æª”æ¡ˆ
    if processed_path != image_path and os.path.exists(processed_path):
        os.remove(processed_path)
    
    # 3. é¸æ“‡æœ€ä½³çµæœï¼ˆåŸºæ–¼æ–‡å­—é•·åº¦å’Œå“è³ªï¼‰
    if results:
        # æŒ‰æ–‡å­—é•·åº¦æ’åºï¼Œé¸æ“‡æœ€é•·çš„çµæœ
        best_result = max(results, key=lambda x: x[2])
        print(f"âœ… é¸æ“‡ {best_result[0]} çš„çµæœ ({best_result[2]} å­—å…ƒ)")
        return best_result[1]
    else:
        return "ç„¡æ³•æå–æ–‡å­—å…§å®¹"


def count_tokens(text: str, model: str = EMBEDDING_MODEL) -> int:
    """è¨ˆç®—æ–‡æœ¬çš„ token æ•¸é‡"""
    try:
        encoding = tiktoken.encoding_for_model(model)
        return len(encoding.encode(text))
    except Exception:
        return len(text) // 3

def smart_text_chunker(text: str, max_tokens: int = CHUNK_SIZE, overlap_tokens: int = CHUNK_OVERLAP) -> List[str]:
    """æ™ºèƒ½æ–‡æœ¬åˆ‡å‰²å™¨"""
    if count_tokens(text) <= max_tokens:
        return [text]

    chunks, current_chunk, current_tokens = [], "", 0
    sentences = re.split(r"[ã€‚ï¼ï¼Ÿï¼›\n]", text)

    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        tok = count_tokens(sentence)
        
        # å¦‚æœå–®å¥éé•·ï¼Œå¼·åˆ¶åˆ‡å‰²
        if tok > max_tokens:
            if current_chunk:
                chunks.append(current_chunk.strip())
                current_chunk, current_tokens = "", 0
            
            # æŒ‰ token å¼·åˆ¶åˆ‡å‰²
            try:
                encoding = tiktoken.encoding_for_model(EMBEDDING_MODEL)
                enc = encoding.encode(sentence)
                for i in range(0, len(enc), max_tokens - overlap_tokens):
                    chunk_tokens = enc[i:i + max_tokens]
                    chunks.append(encoding.decode(chunk_tokens))
            except Exception:
                # å¦‚æœç·¨ç¢¼å¤±æ•—ï¼ŒæŒ‰å­—ç¬¦åˆ‡å‰²
                chunk_size = max_tokens * 3  # ä¼°ç®—å­—ç¬¦æ•¸
                for i in range(0, len(sentence), chunk_size):
                    chunks.append(sentence[i:i + chunk_size])
            continue
        
        # ä¸€èˆ¬ç´¯ç©é‚è¼¯
        if current_tokens + tok > max_tokens:
            chunks.append(current_chunk.strip())
            
            # è™•ç†é‡ç–Š
            if overlap_tokens > 0:
                overlap_text = current_chunk[-overlap_tokens*3:]
                current_chunk = overlap_text + sentence
                current_tokens = count_tokens(current_chunk)
            else:
                current_chunk, current_tokens = sentence, tok
        else:
            current_chunk += sentence + "ã€‚"
            current_tokens += tok
    
    if current_chunk.strip():
        chunks.append(current_chunk.strip())
    
    return chunks

def translate_to_cht(text: str) -> str:
    """æ–‡å­—ç¿»è­¯ï¼ˆéä¸­æ–‡ â†’ ç¹ä¸­ï¼‰"""
    try:
        # ç°¡å–®çš„èªè¨€æª¢æ¸¬
        if any(char in text for char in 'çš„æ˜¯åœ¨æœ‰ä¸€å€‹'):
            return text  # å·²ç¶“æ˜¯ä¸­æ–‡
    except Exception:
        pass

    try:
        resp = openai.ChatCompletion.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": "You are a translator; translate to Traditional Chinese without adding or removing content."},
                {"role": "user", "content": text}
            ],
            temperature=0
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        print(f"ç¿»è­¯å¤±æ•—: {e}")
        return text

# ========= 3. JSON èƒå–è™•ç†å™¨ =========

class UniversalJSONProcessor:
    """é€šç”¨ JSON è™•ç†å™¨"""
    
    @staticmethod
    def extract_text_from_any_structure(data: Any, path: str = "") -> List[str]:
        """å¾ä»»æ„ JSON çµæ§‹ä¸­æå–æ–‡æœ¬"""
        texts = []
        
        if isinstance(data, str):
            if len(data.strip()) > 5:
                texts.append(data.strip())
        elif isinstance(data, dict):
            for key, value in data.items():
                if key.lower() in ['id', 'timestamp', 'created_at', 'updated_at']:
                    continue
                texts.extend(UniversalJSONProcessor.extract_text_from_any_structure(value, f"{path}.{key}"))
        elif isinstance(data, list):
            for i, item in enumerate(data):
                texts.extend(UniversalJSONProcessor.extract_text_from_any_structure(item, f"{path}[{i}]"))
        
        return texts
    
    @staticmethod
    def identify_content_type(data: Dict, filename: str) -> str:
        """è­˜åˆ¥å…§å®¹é¡å‹"""
        filename_lower = filename.lower()
        
        # åŸºæ–¼æª”ååˆ¤æ–·
        if 'é•è¦' in filename or 'violation' in filename_lower:
            return 'violation'
        elif 'å¯ç”¨' in filename or 'allowed' in filename_lower or 'å¾—ä½¿ç”¨' in filename:
            return 'allowed'
        elif 'æ³•è¦' in filename or 'law' in filename_lower or 'ç®¡ç†æ³•' in filename:
            return 'regulation'
        elif 'ä¿å¥åŠŸæ•ˆ' in filename or 'health' in filename_lower:
            return 'health_function'
        elif 'åŒ–å¦å“' in filename or 'cosmetic' in filename_lower:
            return 'cosmetic'
        elif 'ä¸­è—¥' in filename or 'tcm' in filename_lower:
            return 'tcm'
        
        # åŸºæ–¼å…§å®¹çµæ§‹åˆ¤æ–·
        data_str = str(data).lower()
        if 'inappropriate' in data_str or 'ä¸é©ç•¶' in str(data):
            return 'violation'
        elif 'allowed' in data_str or 'å…è¨±' in str(data) or 'å¯ç”¨' in str(data):
            return 'allowed'
        else:
            return 'general'

# ========= 4. å¢å¼·ç‰ˆå‘é‡è³‡æ–™åº« =========

class EnhancedVectorStore:
    def __init__(self, index_path: str = "legal_docs.idx", data_path: str = "legal_docs.json"):
        self.index_path = index_path
        self.data_path = data_path
        self.index = None
        self.metadatas = []
        # -------------------------------------------
        self.sent_transformer = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
        # -------------------------------------------
        
        # åˆ†é¡å„²å­˜ä¸åŒé¡å‹çš„å…§å®¹
        self.violation_patterns = set()
        self.allowed_phrases = set()
        self.regulation_texts = []
        self.health_functions = []
        
        # åŸºç¤å…è¨±ç”¨è©
        self.base_allowed_claims = {
            "å®Œæ•´è£œå……ç‡Ÿé¤Š", "èª¿æ•´é«”è³ª", "ä¿ƒé€²æ–°é™³ä»£è¬", "å¹«åŠ©å…¥ç¡",
            "ä¿è­·æ¶ˆåŒ–é“å…¨æ©Ÿèƒ½", "æ”¹è®Šç´°èŒå¢ç”Ÿæ…‹", "æ’ä¾¿æœ‰æ„Ÿ",
            "ç¶­æŒæ­£å¸¸çš„æ’ä¾¿ç¿’æ…£", "æ’ä¾¿é †æš¢", "æå‡å¸æ”¶æ»‹é¤Šæ¶ˆåŒ–æ©Ÿèƒ½",
            "é’æ˜¥ç¾éº—", "ç‡Ÿé¤Šè£œå……", "è†³é£Ÿè£œå……", "å¥åº·ç¶­æŒ",
            "èƒ½å®Œæ•´è£œå……äººé«”ç‡Ÿé¤Š", "æå‡ç”Ÿç†æ©Ÿèƒ½", "èª¿ç¯€ç”Ÿç†æ©Ÿèƒ½",
            "æ’ä¾¿è¶…æœ‰æ„Ÿ", "çµ¦ä½ æ’ä¾¿é †æš¢æ–°é«”é©—",
            "åœ¨åš´è¬¹çš„ç‡Ÿé¤Šå‡è¡¡èˆ‡ç†±é‡æ§åˆ¶ï¼Œä»¥åŠé©ç•¶çš„é‹å‹•æ¢ä»¶ä¸‹ï¼Œé©é‡æ”å–æœ¬ç”¢å“æœ‰åŠ©æ–¼ä¸æ˜“å½¢æˆé«”è„‚è‚ª"
        }
        
        # åš´æ ¼é•è¦é—œéµè©
        self.strict_violation_keywords = {
            "æ²»ç™‚", "æ²»ç™’", "é†«æ²»", "æ ¹æ²»", "ç™‚æ•ˆ", "è—¥æ•ˆ", "æ¶ˆé™¤ç–¾ç—…",
            "æ²»å¥½", "ç—Šç™’", "æ ¹é™¤", "é†«ç™‚", "è¨ºæ–·", "é é˜²ç–¾ç—…", "æŠ—ç™Œ",
            "é™è¡€ç³–", "é™è¡€å£“", "æ²»ç³–å°¿ç—…", "æ²»é«˜è¡€å£“",
            "æ›¿ä»£æ–¹æ¡ˆ", "æœ€ä½³æ›¿ä»£", "æ²»ç™‚æ›¿ä»£", "é†«ç™‚æ›¿ä»£",
            "æ›¿ä»£ç™‚æ³•", "æ›¿ä»£æ²»ç™‚", "å–ä»£è—¥ç‰©", "ä¸ç”¨åƒè—¥",
            "èƒƒé£Ÿé“é€†æµ", "ç³–å°¿ç—…", "é«˜è¡€å£“", "å¿ƒè‡Ÿç—…", "ç™Œç—‡",
            "è‚ç—…", "è…ç—…", "é—œç¯€ç‚", "æ†‚é¬±ç—‡", "å¤±çœ ç—‡",
            "100%æœ‰æ•ˆ", "å®Œå…¨æ²»ç™’", "æ°¸ä¹…æ ¹æ²»", "ç«‹å³è¦‹æ•ˆ",
            "ä¿è­‰æœ‰æ•ˆ", "çµ•å°æœ‰æ•ˆ", "ç¥å¥‡ç™‚æ•ˆ",
            "æ´»åŒ–æ¯›å›Š", "åˆºæ¿€æ¯›å›Šç´°èƒ", "å¢åŠ æ¯›å›Šè§’è³ªç´°èƒå¢ç”Ÿ",
            "åˆºæ¿€æ¯›å›Šè®“é«®çµ²å†æ¬¡ç”Ÿé•·ä¸æ˜“è½è„«", "åˆºæ¿€æ¯›å›Šä¸èç¸®",
            "å …å›ºæ¯›å›Šåˆºæ¿€æ–°ç”Ÿç§€é«®", "é ­é ‚ä¸å†å…‰ç¦¿ç¦¿", "é ­é ‚ä¸å†å…‰æºœæºœ",
            "é¿å…ç¨€ç–", "é¿å…é«®é‡ç¨€å°‘å•é¡Œ", "æœ‰æ•ˆé é˜²è½é«®/æŠ‘åˆ¶è½é«®/æ¸›å°‘è½é«®",
            "æœ‰æ•ˆé é˜²æ‰é«®/æŠ‘åˆ¶æ‰é«®/æ¸›å°‘æ‰é«®",
            "å¢å¼·(å¢åŠ )è‡ªé«”å…ç–«åŠ›", "å¢å¼·æ·‹å·´å¼•æµ", "ä¿ƒé€²ç´°èƒæ´»å‹•", "æ·±å…¥ç´°èƒè†œä½œç”¨",
            "æ¸›å¼±è§’åŒ–ç´°èƒ", "åˆºæ¿€ç´°èƒå‘¼å¸ä½œç”¨", "æé«˜è‚Œè†šç´°èƒå¸¶æ°§ç‡",
            "é€²å…¥ç”²æ¯ç´°èƒå’Œç”²åºŠæ·±åº¦æ»‹æ½¤", "åˆºæ¿€å¢é•·æ–°çš„å¥åº·ç´°èƒ", "å¢åŠ ç´°èƒæ–°é™³ä»£è¬",
            "ä¿ƒé€²è‚Œè†šç¥ç¶“é†¯èƒºåˆæˆ", "ç¶­æŒä¸Šçš®çµ„ç¹”æ©Ÿèƒ½çš„é‹ä½œ", "é‡å»ºçš®è„‚è†œ", "é‡å»ºè§’è³ªå±¤",
            "ä¿ƒé€²(åˆºæ¿€)è† åŸè›‹ç™½åˆæˆ", "ä¿ƒé€²(åˆºæ¿€)è† åŸè›‹ç™½å¢ç”Ÿ", "ç˜¦èº«", "æ¸›è‚¥", "å»è„‚",
            "æ¸›è„‚", "æ¶ˆè„‚", "ç‡ƒç‡’è„‚è‚ª", "æ¸›ç·©è‡€éƒ¨è‚¥æ²¹å›¤ç©", "é é˜²è„‚è‚ªç´°èƒå †ç©",
            "åˆºæ¿€è„‚è‚ªåˆ†è§£é…µç´ ", "çº–(å­…)é«”", "å¡‘èº«", "é›•å¡‘æ›²ç·š", "æ¶ˆé™¤æ°æ°è‚‰", "æ¶ˆé™¤è´è¶è¢–",
            "å‘Šåˆ¥å°è…¹å©†", "æ¸›å°‘æ©˜çš®çµ„ç¹”", "è±èƒ¸", "éš†ä¹³", "ä½¿èƒ¸éƒ¨å …æŒºä¸ä¸‹å‚",
            "æ„Ÿå—æ‰˜é«˜é›†ä¸­çš„é©šäººæ•ˆæœ", "æ¼‚ç™½", "ä½¿ä¹³æšˆæ¼‚æˆç²‰ç´…è‰²", "ä¸éæ•", "é›¶éæ•",
            "æ¸›éæ•", "æŠ—éæ•", "èˆ’ç·©éæ•", "ä¿®è­·éæ•", "éæ•æ¸¬è©¦", "é†«è—¥ç´š", "é®éœåŠ‘",
            "é®å®šåŠ‘", "æ¶ˆé™¤æµ®è…«", "æ”¹å–„å¾®è¡€ç®¡å¾ªç’°", "åŠŸèƒ½å¼·åŒ–å¾®è¡€ç®¡", "å¢åŠ è¡€ç®¡å«æ°§é‡æé«˜è‚Œè†šå¸¶æ°§ç‡",
            "é é˜²(é˜²æ­¢)è‚¥èƒ–ç´‹", "é é˜²(é˜²æ­¢)å¦Šå¨ ç´‹", "ç·©æ¸›å¦Šå¨ ç´‹ç”Ÿç”¢"
        }
        
        # ä¸Šä¸‹æ–‡æ•æ„Ÿæ¨¡å¼
        self.context_sensitive_patterns = {
            "å°ˆå®¶æ¨è–¦": ["æ²»ç™‚", "ç–¾ç—…", "æ›¿ä»£", "é†«ç™‚"],
            "ç§‘å­¸å¯¦è­‰": ["æ²»ç™‚", "ç™‚æ•ˆ", "é†«ç™‚"],
            "åœ‹å¤–ç ”ç©¶": ["æ²»ç™‚", "ç™‚æ•ˆ", "é†«ç™‚"],
            "è‡¨åºŠè­‰å¯¦": ["æ²»ç™‚", "ç™‚æ•ˆ", "é†«ç™‚"]
        }
        
        # ç”¢å“é¡åˆ¥é—œéµå­—
        self.product_type_map = {
            "food": ["é£Ÿå“", "supplement", "è†³é£Ÿ", "ä»£é¤"],
            "cosmetic": ["åŒ–å¦å“", "ç¾ç™½", "skin", "cream", "toner"],
            "drug": ["è—¥", "æ²»ç™‚", "è—¥å“", "è—¥ç‰©"]
        }

    def _cluster_representative_texts(self, texts: List[str], max_clusters: int = 5) -> List[str]:
        if len(texts) <= max_clusters:
            return texts
    
        embeddings = self.sent_transformer.encode(texts)
        n_clusters = min(max_clusters, len(texts))
        kmeans = KMeans(n_clusters=n_clusters, random_state=42)
        kmeans.fit(embeddings)
        labels = kmeans.labels_
        centroids = kmeans.cluster_centers_
    
        representatives = []
        for cluster_id in range(n_clusters):
            cluster_indices = [i for i, lbl in enumerate(labels) if lbl == cluster_id]
            cluster_embeddings = [embeddings[i] for i in cluster_indices]
            centroid = centroids[cluster_id]
            distances = [np.linalg.norm(e - centroid) for e in cluster_embeddings]
            rep_idx = cluster_indices[np.argmin(distances)]
            group_text = "ã€‚".join([texts[i] for i in cluster_indices])
            representatives.append(group_text)
    
        return representatives
    
    def identify_product_type(self, text: str) -> str:
        """è­˜åˆ¥ç”¢å“é¡å‹"""
        text_lower = text.lower()
        for product_type, keywords in self.product_type_map.items():
            if any(kw.lower() in text_lower for kw in keywords):
                return product_type
        return "food"
    
    def load_json_files(self, json_folder: str) -> List[Dict[str, Any]]:
        """è¼‰å…¥ JSON æ–‡ä»¶"""
        all_data = []
        json_files = glob.glob(os.path.join(json_folder, "*.json"))
        
        if not json_files:
            raise ValueError(f"è³‡æ–™å¤¾ä¸­æ²’æœ‰ JSON æ–‡ä»¶: {json_folder}")
        
        print(f"ç™¼ç¾ {len(json_files)} å€‹ JSON æ–‡ä»¶")
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                processed_data = self.process_universal_json(data, os.path.basename(json_file))
                all_data.extend(processed_data)
                print(f"å·²è™•ç†: {os.path.basename(json_file)} - {len(processed_data)} ç­†è³‡æ–™")
                
            except Exception as e:
                print(f"è™•ç† {json_file} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        return all_data
    
    def process_universal_json(self, data: Dict[str, Any], filename: str) -> List[Dict[str, Any]]:
        """è™•ç†é€šç”¨ JSON æ•¸æ“š"""
        processed_items = []
        content_type = UniversalJSONProcessor.identify_content_type(data, filename)
        
        # æå–æ‰€æœ‰æ–‡æœ¬å…§å®¹
        all_texts = UniversalJSONProcessor.extract_text_from_any_structure(data)
        
        for i, text in enumerate(all_texts):
            if len(text.strip()) < 10:
                continue
            
            token_count = count_tokens(text)
            
            if token_count > MAX_TOKENS:
                print(f"æ–‡æœ¬éé•· ({token_count} tokens)ï¼Œé€²è¡Œåˆ‡å‰²...")
                chunks = smart_text_chunker(text, CHUNK_SIZE, CHUNK_OVERLAP)
                print(f"åˆ‡å‰²ç‚º {len(chunks)} å€‹ç‰‡æ®µ")
                
                for chunk_idx, chunk in enumerate(chunks):
                    item_id = f"{filename}_item_{i}_chunk_{chunk_idx}"
                    
                    # åˆ†é¡è™•ç†
                    self._categorize_content(chunk, content_type)
                    
                    processed_items.append({
                        'id': item_id,
                        'text': chunk,
                        'source_file': filename,
                        'content_type': content_type,
                        'type': f'{content_type}_content',
                        'chunk_info': {
                            'original_item': i,
                            'chunk_index': chunk_idx,
                            'total_chunks': len(chunks),
                            'original_length': token_count
                        }
                    })
            else:
                item_id = f"{filename}_item_{i}"
                
                # åˆ†é¡è™•ç†
                self._categorize_content(text, content_type)
                
                processed_items.append({
                    'id': item_id,
                    'text': text,
                    'source_file': filename,
                    'content_type': content_type,
                    'type': f'{content_type}_content'
                })
        
        # è™•ç†çµæ§‹åŒ–æ•¸æ“š
        if isinstance(data, dict):
            processed_items.extend(self._process_structured_data(data, filename, content_type))
        
        return processed_items
    
    def _categorize_content(self, text: str, content_type: str):
        """åˆ†é¡å…§å®¹åˆ°å°æ‡‰çš„é›†åˆ"""
        text_stripped = text.strip()
        
        if content_type == 'violation':
            if len(text_stripped) < 100:
                self.violation_patterns.add(text_stripped)
        elif content_type == 'allowed':
            if len(text_stripped) < 50:
                self.allowed_phrases.add(text_stripped)
        elif content_type == 'regulation':
            self.regulation_texts.append(text_stripped)
        elif content_type == 'health_function':
            self.health_functions.append(text_stripped)
    
    def _process_structured_data(self, data: Dict, filename: str, content_type: str) -> List[Dict]:
        """è™•ç†çµæ§‹åŒ–æ•¸æ“š"""
        items = []
        
        patterns = [
            ('cases', 'case'),
            ('items', 'item'), 
            ('examples', 'example'),
            ('categories', 'category'),
            ('violations', 'violation'),
            ('regulations', 'regulation')
        ]
        
        for pattern_key, item_type in patterns:
            if pattern_key in data and isinstance(data[pattern_key], list):
                for i, item in enumerate(data[pattern_key]):
                    if isinstance(item, dict):
                        content_fields = ['content', 'text', 'description', 'å…§å®¹', 'å»£å‘Šå…§å®¹', 'ad_content']
                        main_content = ""
                        
                        for field in content_fields:
                            if field in item and item[field]:
                                main_content = str(item[field])
                                break
                        
                        if not main_content:
                            main_content = json.dumps(item, ensure_ascii=False)
                        
                        token_count = count_tokens(main_content)
                        
                        if token_count > MAX_TOKENS:
                            chunks = smart_text_chunker(main_content, CHUNK_SIZE, CHUNK_OVERLAP)
                            
                            for chunk_idx, chunk in enumerate(chunks):
                                self._categorize_content(chunk, content_type)
                                
                                items.append({
                                    'id': f"{filename}_{item_type}_{i}_chunk_{chunk_idx}",
                                    'text': chunk,
                                    'source_file': filename,
                                    'content_type': content_type,
                                    'item_type': item_type,
                                    'type': f'structured_{item_type}',
                                    'chunk_info': {
                                        'original_item': i,
                                        'chunk_index': chunk_idx,
                                        'total_chunks': len(chunks),
                                        'original_length': token_count
                                    }
                                })
                        else:
                            self._categorize_content(main_content, content_type)
                            
                            items.append({
                                'id': f"{filename}_{item_type}_{i}",
                                'text': main_content,
                                'source_file': filename,
                                'content_type': content_type,
                                'item_type': item_type,
                                'type': f'structured_{item_type}'
                            })
        
        return items
    
    def build(self, json_folder: str):
        """å»ºç«‹å‘é‡ç´¢å¼•"""
        if not os.path.isdir(json_folder):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°è³‡æ–™å¤¾: {json_folder}")
        
        # è¼‰å…¥ä¸¦è™•ç† JSON æ–‡ä»¶
        all_data = self.load_json_files(json_folder)
        
        if not all_data:
            raise ValueError("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½• JSON æ–‡ä»¶")
        
        # åˆä½µåŸºç¤å…è¨±ç”¨è©
        self.allowed_phrases.update(self.base_allowed_claims)
        
        print(f"å»ºç«‹ç´¢å¼•ï¼šå…±è™•ç† {len(all_data)} å€‹è³‡æ–™é …ç›®")
        print(f"é•è¦æ¨¡å¼: {len(self.violation_patterns)} å€‹")
        print(f"å…è¨±ç”¨è©: {len(self.allowed_phrases)} å€‹")
        print(f"æ³•è¦æ¢æ–‡: {len(self.regulation_texts)} å€‹")
        print(f"ä¿å¥åŠŸæ•ˆ: {len(self.health_functions)} å€‹")
        
        self.metadatas = []
        embeddings = []
        
        for item in all_data:
            try:
                text = item['text']
                token_count = count_tokens(text)
                
                if token_count > MAX_TOKENS:
                    print(f"è­¦å‘Šï¼šé …ç›® {item['id']} ä»ç„¶éé•· ({token_count} tokens)ï¼Œè·³é")
                    continue
                
                # ç”ŸæˆåµŒå…¥å‘é‡
                emb = openai.Embedding.create(
                    model=EMBEDDING_MODEL,
                    input=text
                )['data'][0]['embedding']
                
                embeddings.append(emb)
                self.metadatas.append(item)
                
                if len(embeddings) % 50 == 0:
                    print(f"å·²è™•ç† {len(embeddings)} å€‹é …ç›®...")
                
            except Exception as e:
                print(f"è™•ç†é …ç›® {item.get('id', 'unknown')} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue
        
        if not embeddings:
            raise ValueError("æ²’æœ‰æˆåŠŸè™•ç†ä»»ä½•é …ç›®")
        
        # å»ºç«‹ FAISS ç´¢å¼•
        index = faiss.IndexFlatIP(EMBEDDING_DIM)
        index.add(np.array(embeddings, dtype='float32'))
        self.index = index
        
        # å„²å­˜ç´¢å¼•å’Œå…ƒæ•¸æ“š
        faiss.write_index(self.index, self.index_path)
        with open(self.data_path, 'w', encoding='utf-8') as f:
            json.dump(self.metadatas, f, ensure_ascii=False, indent=2)
        
        print(f"ç´¢å¼•èˆ‡å…ƒè³‡æ–™å·²å„²å­˜ã€‚ç¸½å…±è™•ç†äº† {len(embeddings)} å€‹é …ç›®ã€‚")
        
        chunked_items = [item for item in self.metadatas if 'chunk_info' in item]
        if chunked_items:
            print(f"å…¶ä¸­ {len(chunked_items)} å€‹é …ç›®ä¾†è‡ªæ–‡æœ¬åˆ‡å‰²")
    
    def load(self):
        """è¼‰å…¥ç¾æœ‰çš„ç´¢å¼•å’Œå…ƒæ•¸æ“š"""
        if not os.path.exists(self.index_path) or not os.path.exists(self.data_path):
            raise FileNotFoundError("ç´¢å¼•æˆ–å…ƒè³‡æ–™æª”æ¡ˆä¸å­˜åœ¨ï¼Œè«‹å…ˆå»ºç«‹ç´¢å¼•ï¼ˆä½¿ç”¨ --rebuildï¼‰ã€‚")
        
        self.index = faiss.read_index(self.index_path)
        with open(self.data_path, 'r', encoding='utf-8') as f:
            self.metadatas = json.load(f)
        
        # é‡å»ºåˆ†é¡æ•¸æ“š
        self.allowed_phrases.update(self.base_allowed_claims)
        
        for item in self.metadatas:
            content_type = item.get('content_type', 'general')
            text = item.get('text', '').strip()
            
            if content_type == 'violation' and text and len(text) < 100:
                self.violation_patterns.add(text)
            elif content_type == 'allowed' and text and len(text) < 50:
                self.allowed_phrases.add(text)
            elif content_type == 'regulation' and text:
                self.regulation_texts.append(text)
            elif content_type == 'health_function' and text:
                self.health_functions.append(text)
        
        print(f"å·²è¼‰å…¥ {len(self.metadatas)} ç­†æ³•è¦å…ƒè³‡æ–™ã€‚")
        print(f"é•è¦æ¨¡å¼: {len(self.violation_patterns)} å€‹")
        print(f"å…è¨±ç”¨è©: {len(self.allowed_phrases)} å€‹")
        
        chunked_items = [item for item in self.metadatas if 'chunk_info' in item]
        if chunked_items:
            print(f"å…¶ä¸­ {len(chunked_items)} å€‹é …ç›®ä¾†è‡ªæ–‡æœ¬åˆ‡å‰²")
    
    def query(self, query_text: str, top_k: int = 5, product_type: str = "food") -> List[dict]:
        """æŸ¥è©¢æœ€ç›¸é—œçš„æ³•è¦æ–‡ä»¶"""
        if self.index is None:
            raise ValueError("ç´¢å¼•æœªè¼‰å…¥ï¼Œè«‹å…ˆå»ºç«‹æˆ–è¼‰å…¥ç´¢å¼•")
        
        # ç”ŸæˆæŸ¥è©¢åµŒå…¥å‘é‡
        q_emb = openai.Embedding.create(
            model=EMBEDDING_MODEL,
            input=query_text
        )['data'][0]['embedding']
        
        # æœç´¢æœ€ç›¸ä¼¼çš„æ–‡ä»¶
        D, I = self.index.search(np.array([q_emb], dtype='float32'), top_k * 2)
        
        # æ ¹æ“šç”¢å“é¡å‹éæ¿¾çµæœ
        results = []
        for i in I[0]:
            if i < len(self.metadatas):
                meta = self.metadatas[i]
                # ç°¡åŒ–éæ¿¾é‚è¼¯ï¼Œä¸»è¦åŸºæ–¼å…§å®¹ç›¸é—œæ€§
                results.append(meta)
                if len(results) >= top_k:
                    break
        
        return results[:top_k]
    
    def enhanced_compliance_check(self, ad_text: str) -> Dict[str, Any]:
        """å¢å¼·çš„åˆè¦æª¢æŸ¥"""
        ad_text_lower = ad_text.lower()
        
        # æª¢æŸ¥åš´æ ¼é•è¦é—œéµè©
        strict_violations = [kw for kw in self.strict_violation_keywords if kw in ad_text]
        
        # æª¢æŸ¥ä¸Šä¸‹æ–‡æ•æ„Ÿçµ„åˆ
        context_violations = []
        for trigger, sensitive_words in self.context_sensitive_patterns.items():
            if trigger in ad_text:
                for word in sensitive_words:
                    if word in ad_text:
                        context_violations.append(f"{trigger}+{word}")
        
        # æª¢æŸ¥é†«ç™‚æ›¿ä»£æ–¹æ¡ˆ
        medical_substitute_patterns = [
            "æ›¿ä»£æ–¹æ¡ˆ.*ç–¾ç—…", "æ›¿ä»£æ–¹æ¡ˆ.*ç—‡", "æœ€ä½³æ›¿ä»£.*ç–¾ç—…", 
            "å°ˆå®¶æ¨è–¦.*æ²»ç™‚", "å°ˆå®¶æ¨è–¦.*ç–¾ç—…", "ç§‘å­¸å¯¦è­‰.*ç™‚æ•ˆ"
        ]
        
        substitute_violations = []
        for pattern in medical_substitute_patterns:
            if re.search(pattern, ad_text):
                substitute_violations.append(pattern)
        
        # æª¢æŸ¥å…è¨±ç”¨è©
        found_allowed = [phrase for phrase in self.allowed_phrases if phrase in ad_text]
        
        # æª¢æŸ¥å®˜æ–¹èªè­‰
        has_official_approval = bool(re.search(r'è¡›ç¦éƒ¨.*å­—è™Ÿ|è¡›ç¦éƒ¨èªè­‰|è¡›ç½².*å­—ç¬¬.*è™Ÿ', ad_text))
        
        # è¨ˆç®—é¢¨éšªåˆ†æ•¸
        risk_score = 0
        
        if strict_violations:
            risk_score += len(strict_violations) * 50
        
        if context_violations:
            risk_score += len(context_violations) * 40
        
        if substitute_violations:
            risk_score += len(substitute_violations) * 60
        
        if (strict_violations or context_violations or substitute_violations) and not has_official_approval:
            risk_score += 20
        
        if found_allowed and risk_score < 70:
            risk_score = max(0, risk_score - len(found_allowed) * 5)
        
        risk_score = min(95, max(0, risk_score))
        
        return {
            'strict_violations': strict_violations,
            'context_violations': context_violations,
            'substitute_violations': substitute_violations,
            'allowed_phrases_found': found_allowed,
            'has_official_approval': has_official_approval,
            'risk_score': risk_score,
            'risk_level': 'high' if risk_score >= 80 else 'medium' if risk_score >= 40 else 'low',
            'product_type': self.identify_product_type(ad_text)
        }

# ========= 5. å¢å¼·ç‰ˆå»£å‘Šæª¢æ¸¬ç³»çµ±ï¼ˆæ”¯æ´åœ–ç‰‡è¼¸å…¥ï¼‰=========

class EnhancedAdvertisementDetector:
    def __init__(self, vector_store: EnhancedVectorStore):
        """åˆå§‹åŒ–å¢å¼·ç‰ˆå»£å‘Šæª¢æ¸¬ç³»çµ±"""
        self.vector_store = vector_store
        self.colpali_processor = None
        self._init_colpali()
    
    def _init_colpali(self):
        """åˆå§‹åŒ– ColPali è™•ç†å™¨"""
        try:
            self.colpali_processor = ColPaliImageProcessor()
            print("âœ… ColPali åœ–ç‰‡è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"âŒ ColPali åˆå§‹åŒ–å¤±æ•—: {e}")
            print("âš ï¸  å°‡åƒ…æ”¯æ´æ–‡å­—è¼¸å…¥æ¨¡å¼")
            self.colpali_processor = None
    
    def process_input(self, input_data: Union[str, Path], input_type: str = "auto") -> str:
        """è™•ç†è¼¸å…¥æ•¸æ“šï¼ˆæ–‡å­—æˆ–åœ–ç‰‡ï¼‰"""
        if input_type == "auto":
            # è‡ªå‹•æª¢æ¸¬è¼¸å…¥é¡å‹
            if isinstance(input_data, str):
                if os.path.isfile(input_data) and input_data.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                    input_type = "image"
                else:
                    input_type = "text"
            else:
                input_type = "text"
        
        if input_type == "image":
            return self._process_image_input(input_data)
        else:
            return self._process_text_input(input_data)
    
    def _process_text_input(self, text: str) -> str:
        """è™•ç†æ–‡å­—è¼¸å…¥"""
        print(f"ğŸ“ è™•ç†æ–‡å­—è¼¸å…¥: {text[:100]}...")
        return translate_to_cht(text)
    
    def _process_image_input(self, image_path: str) -> str:
        """è™•ç†åœ–ç‰‡è¼¸å…¥"""
        if not self.colpali_processor:
            raise ValueError("âŒ ColPali è™•ç†å™¨æœªåˆå§‹åŒ–ï¼Œç„¡æ³•è™•ç†åœ–ç‰‡ã€‚è«‹æª¢æŸ¥ ColPali å®‰è£æˆ–ä½¿ç”¨æ–‡å­—è¼¸å…¥æ¨¡å¼ã€‚")
        
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°åœ–ç‰‡æª”æ¡ˆ: {image_path}")
        
        print(f"ğŸ–¼ï¸ æ­£åœ¨è™•ç†åœ–ç‰‡: {image_path}")
        
        try:
            extracted_text = self.colpali_processor.extract_text_from_image(image_path)
            
            if not extracted_text or len(extracted_text.strip()) < 10:
                raise ValueError("âŒ ColPali ç„¡æ³•å¾åœ–ç‰‡ä¸­æå–è¶³å¤ çš„æ–‡å­—å…§å®¹ã€‚å»ºè­°ï¼š\n1. ç¢ºä¿åœ–ç‰‡æ¸…æ™°å¯è®€\n2. ä½¿ç”¨å°ˆé–€çš„ OCR å·¥å…·\n3. æ‰‹å‹•è¼¸å…¥æ–‡å­—å…§å®¹")
            
            print(f"âœ… æˆåŠŸå¾åœ–ç‰‡æå–æ–‡å­— ({len(extracted_text)} å­—å…ƒ)")
            translated_text = translate_to_cht(extracted_text)
            
            # é¡¯ç¤ºæœ€çµ‚è™•ç†çµæœ
            print("ğŸ”„ ç¿»è­¯å¾Œçš„æ–‡å­—å…§å®¹:")
            print("=" * 60)
            print(translated_text)
            print("=" * 60)
            
            return translated_text
            
        except Exception as e:
            print(f"âŒ åœ–ç‰‡è™•ç†å¤±æ•—: {e}")
            raise
    
    def detect_advertisement_compliance(self, input_data: Union[str, Path], input_type: str = "auto") -> Dict[str, Any]:
        """æª¢æ¸¬å»£å‘Šåˆè¦æ€§"""
        try:
            print("\n" + "="*60)
            print("ğŸ” é–‹å§‹å»£å‘Šåˆè¦æ€§æª¢æ¸¬")
            print("="*60)
            
            # è™•ç†è¼¸å…¥
            processed_text = self.process_input(input_data, input_type)
            
            if not processed_text or len(processed_text.strip()) < 5:
                return {
                    'error': 'è™•ç†å¾Œçš„æ–‡å­—å…§å®¹éçŸ­ï¼Œç„¡æ³•é€²è¡Œæœ‰æ•ˆæª¢æ¸¬',
                    'input_type': input_type,
                    'timestamp': datetime.utcnow().isoformat()
                }
            
            print(f"ğŸ“‹ æœ€çµ‚æª¢æ¸¬æ–‡å­— ({len(processed_text)} å­—å…ƒ):")
            print("-" * 40)
            print(processed_text)
            print("-" * 40)
            
            # ä½¿ç”¨åŸæœ‰çš„æª¢æ¸¬é‚è¼¯
            print("ğŸ”¬ åŸ·è¡Œåˆè¦æ€§åˆ†æ...")
            result = strict_determine_legality(processed_text, self.vector_store)
            
            # æ·»åŠ è¼¸å…¥é¡å‹ä¿¡æ¯
            result['input_type'] = input_type
            result['original_input'] = str(input_data)
            
            if input_type == "image":
                result['image_path'] = str(input_data)
                result['extracted_text'] = processed_text
            
            print("âœ… åˆè¦æ€§æª¢æ¸¬å®Œæˆ")
            return result
            
        except Exception as e:
            error_msg = f"æª¢æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}"
            print(f"âŒ {error_msg}")
            return {
                'error': error_msg,
                'input_type': input_type,
                'original_input': str(input_data),
                'timestamp': datetime.utcnow().isoformat()
            }

# ========= 6. ä¸»åˆ¤æ–·å‡½æ•¸ =========

def strict_determine_legality(ad_text: str, vs: EnhancedVectorStore) -> dict:
    """åš´æ ¼åˆæ³•æ€§åˆ¤æ–·å‡½æ•¸"""
    # ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡
    ad_text = translate_to_cht(ad_text)
    
    # å¢å¼·åˆè¦æª¢æŸ¥
    compliance_check = vs.enhanced_compliance_check(ad_text)
    
    # æª¢ç´¢ç›¸é—œæ³•è¦
    contexts = vs.query(ad_text, top_k=5, product_type=compliance_check["product_type"])
    
    # æº–å‚™ vector store æ–‡ä»¶ ID åˆ—è¡¨
    vector_store_ids = []
    for c in contexts:
        doc_id = c.get('id', c.get('source_file', 'unknown'))
        if 'chunk_info' in c:
            chunk_info = c['chunk_info']
            doc_id += f"_chunk_{chunk_info['chunk_index']+1}/{chunk_info['total_chunks']}"
        vector_store_ids.append(doc_id)
    
    # æ ¹æ“šæ™ºèƒ½æª¢æ¸¬çµæœèª¿æ•´åˆ¤æ–·é‚è¼¯
    risk_level = compliance_check['risk_level']
    risk_score = compliance_check['risk_score']
    allowed_phrases = compliance_check['allowed_phrases_found']
    has_approval = compliance_check['has_official_approval']
    
    # è¨­å®šç³»çµ±æç¤º
    system_prompt = f"""
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ”¿åºœæ³•è¦å¯©æ ¸å“¡ï¼Œä»»å‹™æ˜¯åˆ†æå»£å‘Šæ–‡å­—æ˜¯å¦é•åã€Šé£Ÿå“å®‰å…¨è¡›ç”Ÿç®¡ç†æ³•ã€‹ç¬¬28æ¢è¦å®šï¼Œæ˜¯å¦é•åã€Šå¥åº·é£Ÿå“ç®¡ç†æ³•ã€‹ç¬¬14æ¢è¦å®šï¼Œæ˜¯å¦é•åã€ŠåŒ–ç²§å“è¡›ç”Ÿç®¡ç†æ³•ã€‹ç¬¬10æ¢è¦å®šï¼Œæ˜¯å¦é•åã€Šè—¥äº‹æ³•ã€‹ç¬¬66ã€68ã€69æ¢è¦å®šã€æ˜¯å¦é•åã€Šé†«ç™‚å™¨æç®¡ç†æ³•ã€‹ç¬¬6ã€40ã€41ã€46æ¢è¦å®šã€‚
å°¤å…¶æ¶‰åŠã€Œèª‡å¤§ç™‚æ•ˆã€ã€ã€Œè™›å‡å®£ç¨±ã€ã€ã€Œæœªç¶“è¨±å¯é†«ç™‚ç”¨èªã€ã€ã€Œæ¶‰åŠé†«ç™‚æ•ˆèƒ½ã€ã€ã€Œèª‡å¼µè—¥ç‰©å®‰å…¨æ€§ã€ã€‚
ä½ å°‡æ ¹æ“šæä¾›çš„å»£å‘Šå…§å®¹èˆ‡æ³•è¦è³‡æ–™ï¼Œé€²è¡Œé€æ­¥é¢¨éšªè©•ä¼°èˆ‡é•æ³•æ©Ÿç‡åˆ¤æ–·ï¼Œ**å›æ‡‰éœ€ç¬¦åˆçµæ§‹èˆ‡æ­¥é©ŸæŒ‡å¼•ï¼Œä¸¦åƒ…åˆ†æå¯¦éš›å­˜åœ¨çš„æ–‡å­—å…§å®¹**ã€‚

---

## è©•ä¼°ä»»å‹™ç›®æ¨™

1. ç†è§£å»£å‘Šå¯¦éš›ä¸Šä¸‹æ–‡æ˜¯å¦ç‚ºæè¿°å•†å“ã€‚
2. å¦‚ç¢ºå®šå»£å‘Šæ–‡å­—ç‚ºæè¿°å•†å“ï¼Œå¾ä¸­æŠ½å–å¯¦éš›å­˜åœ¨çš„æè¿°æˆ–ç”¨èªã€‚
3. ä¾æ“šè³‡æ–™åº«æä¾›çš„æ³•è¦ï¼æ¡ˆä¾‹æ–‡æœ¬æ¯”å°æ˜¯å¦æ§‹æˆé•è¦ã€‚
4. ä¾ç…§æ™ºèƒ½æª¢æ¸¬è¼¸å‡ºçš„é¢¨éšªè³‡è¨Šä»¥åŠä½ çš„åˆ¤æ–·ï¼Œç¶œåˆæ¨ä¼°é•æ³•é¢¨éšªç™¾åˆ†æ¯”ï¼ˆåƒ…å…è¨±ï¼š10%ã€30%ã€50%ã€70%ã€90%ï¼‰ã€‚
5. å›æ‡‰æ‡‰åŒ…å«æ¯å€‹åˆ†ææ­¥é©Ÿçš„ä¾æ“šèˆ‡çµæœã€‚

---

## æª¢æ¸¬æ­¥é©Ÿï¼ˆè«‹ä¾åºé€æ­¥å®Œæˆï¼‰

1. **åˆ¤æ–·å»£å‘Šæ•´æ®µå…§å®¹æ˜¯å¦åœ¨æè¿°å•†å“**
   - åœ¨é é¢å¦‚æœå‡ºç¾å¾ˆå¤šä¸åŒç¨®é¡çš„å•†å“æˆ–åˆ†é¡ï¼Œå°±ä¸æ˜¯åœ¨æè¿°å•†å“ (å¦‚ï¼šé€£èº«è¡£ åŒ…å·¾ï¼åŒ…è¢« ç«¥è¥ª/æ‰‹è…³å¥— ç«¥é‹ è¤²è¤²/å¸½å­ ç©¿æ­é…ä»¶ ç¦®ç›’å°ˆå€ å¬°å¹¼å…’æ¸…æ½” æ¿•ç´™å·¾ ç´—å¸ƒ/æ£‰å·¾ æ¿•å·¾åŠ ç†±å™¨ å¥¶ç“¶è”¬æœæ´—æ½”æ¶²/æ´—ç¢—æ¶²)ã€‚
   - å°±ç®—åªæœ‰åŒ…å«æˆåˆ†ï¼Œä½†ç„¡åŒ…å«åŠŸæ•ˆã€ä½¿ç”¨æ–¹æ³•ï¼Œåªè¦æˆåˆ†ä¸é•æ³•ï¼Œé€™å€‹å»£å‘Šå…§å®¹å°±ä¸ç®—æè¿°å•†å“ï¼Œä¸¦å°‡æœ€çµ‚åˆ¤å®šçš„é•æ³•æ©Ÿç‡é™è‡³æœ€ä½ã€‚
   - è‹¥ä¸æ˜¯æè¿°å•†å“ï¼Œå‰‡å›æ‡‰è³‡æ–™ä¸è¶³ä»¥åˆ¤æ–·æ˜¯å¦ç‚ºé•æ³•ï¼Œä¸¦å°‡æ™ºèƒ½åˆ¤æ–·é¢¨éšªæ¨™è¨»ç‚º: lowã€‚
   - è‹¥æ˜¯æè¿°å•†å“ï¼Œå‰‡é–‹å§‹ä»¥ä¸‹æ­¥é©Ÿã€‚
2. **æª¢æŸ¥æ˜¯å¦å‡ºç¾å…è¨±ç”¨è©ï¼Ÿ**
   - ä¾‹å¦‚ï¼šã€Œå®Œæ•´è£œå……ç‡Ÿé¤Šã€ã€Œèª¿æ•´é«”è³ªã€ã€Œä¿ƒé€²æ–°é™³ä»£è¬ã€ã€Œå¹«åŠ©å…¥ç¡ã€ã€Œä¿è­·æ¶ˆåŒ–é“å…¨æ©Ÿèƒ½ã€ã€Œæ”¹è®Šç´°èŒå¢ç”Ÿæ…‹ã€ã€Œæ’ä¾¿æœ‰æ„Ÿã€ã€Œç¶­æŒæ­£å¸¸çš„æ’ä¾¿ç¿’æ…£ã€ã€Œæ’ä¾¿é †æš¢ã€
    ã€Œæå‡å¸æ”¶æ»‹é¤Šæ¶ˆåŒ–æ©Ÿèƒ½ã€ã€Œé’æ˜¥ç¾éº—ã€ã€Œç‡Ÿé¤Šè£œå……ã€ã€Œè†³é£Ÿè£œå……ã€ã€Œå¥åº·ç¶­æŒã€ã€Œèƒ½å®Œæ•´è£œå……äººé«”ç‡Ÿé¤Šã€ã€Œæå‡ç”Ÿç†æ©Ÿèƒ½ã€ã€Œèª¿ç¯€ç”Ÿç†æ©Ÿèƒ½ã€ã€Œæ’ä¾¿è¶…æœ‰æ„Ÿã€
    ã€Œçµ¦ä½ æ’ä¾¿é †æš¢æ–°é«”é©—ã€ã€Œåœ¨åš´è¬¹çš„ç‡Ÿé¤Šå‡è¡¡èˆ‡ç†±é‡æ§åˆ¶ï¼Œä»¥åŠé©ç•¶çš„é‹å‹•æ¢ä»¶ä¸‹ï¼Œé©é‡æ”å–æœ¬ç”¢å“æœ‰åŠ©æ–¼ä¸æ˜“å½¢æˆé«”è„‚è‚ªã€ç­‰ã€‚
   - è‹¥å‡ºç¾ï¼Œè«‹åˆ—èˆ‰ä¸¦èªªæ˜å…¶åˆæ³•æ€§åƒè€ƒã€‚
3. **æª¢æŸ¥æ˜¯å¦å‡ºç¾é•è¦ç”¨è©ï¼Ÿ**
   - ä¾‹å¦‚ï¼šã€Œå…¨æ–¹ä½ã€ã€Œå…¨é¢ã€ã€Œè¶…èƒ½ã€ã€Œæ²»ç™‚ã€ã€Œæ²»ç™’ã€ã€Œé†«æ²»ã€ã€Œæ ¹æ²»ã€ã€Œç™‚æ•ˆã€ã€Œè—¥æ•ˆã€ã€Œæ¶ˆé™¤ç–¾ç—…ã€
    ã€Œæ²»å¥½ã€ã€Œç—Šç™’ã€ã€Œæ ¹é™¤ã€ã€Œé†«ç™‚ã€ã€Œè¨ºæ–·ã€ã€Œé é˜²ç–¾ç—…ã€ã€ŒæŠ—ç™Œã€
    ã€Œé™è¡€ç³–ã€ã€Œé™è¡€å£“ã€ã€Œæ²»ç³–å°¿ç—…ã€ã€Œæ²»é«˜è¡€å£“ã€ã€Œé‚Šç¡é‚Šç˜¦ã€
    ã€Œæ›¿ä»£æ–¹æ¡ˆã€ã€Œæœ€ä½³æ›¿ä»£ã€ã€Œæ²»ç™‚æ›¿ä»£ã€ã€Œé†«ç™‚æ›¿ä»£ã€
    ã€Œæ›¿ä»£ç™‚æ³•ã€ã€Œæ›¿ä»£æ²»ç™‚ã€ã€Œå–ä»£è—¥ç‰©ã€ã€Œä¸ç”¨åƒè—¥ã€
    ã€Œèƒƒé£Ÿé“é€†æµã€ã€Œç³–å°¿ç—…ã€ã€Œé«˜è¡€å£“ã€ã€Œå¿ƒè‡Ÿç—…ã€ã€Œç™Œç—‡ã€
    ã€Œè‚ç—…ã€ã€Œè…ç—…ã€ã€Œé—œç¯€ç‚ã€ã€Œæ†‚é¬±ç—‡ã€ã€Œå¤±çœ ç—‡ã€
    ã€Œ100%æœ‰æ•ˆã€ã€Œå®Œå…¨æ²»ç™’ã€ã€Œæ°¸ä¹…æ ¹æ²»ã€ã€Œç«‹å³è¦‹æ•ˆã€
    ã€Œä¿è­‰æœ‰æ•ˆã€ã€Œçµ•å°æœ‰æ•ˆã€ã€Œç¥å¥‡ç™‚æ•ˆã€ç­‰ã€‚
   - è‹¥æœ‰ï¼Œè«‹æ¨™æ˜å¯¦éš›å¥å­èˆ‡é•è¦è©ã€‚
   - ä½†è‹¥å‡ºç¾ä½†èˆ‡ç”¢å“ç„¡é—œï¼ˆå¦‚é é¢åˆ†é¡åç¨±ï¼‰ï¼Œè«‹èªªæ˜ä¸¦å»é™¤æ™ºèƒ½åˆ¤æ–·çš„é¢¨éšªã€‚
   - è‹¥å‡ºç¾ä¸”èˆ‡æè¿°ç”¢å“åŠŸæ•ˆæœ‰é—œï¼Œå„˜ç®¡æœ‰å‡ºç¾å…è¨±ç”¨è©ï¼Œä»é ˆæé«˜æœ€çµ‚åˆ¤æ–·çš„é•æ³•æ©Ÿç‡ã€‚
4. **æª¢æŸ¥æ˜¯å¦æœ‰ä¸Šä¸‹æ–‡é•è¦çµ„åˆï¼Ÿ**
   - å¦‚ï¼šã€Œæ›¿ä»£æ–¹æ¡ˆã€+ã€ŒXç–¾ç—…ã€ã€ã€Œæ›¿ä»£æ–¹æ¡ˆã€+ã€ŒXç—‡ã€ã€ã€Œæœ€ä½³æ›¿ä»£ã€+ã€ŒXç–¾ç—…ã€ã€ã€Œå°ˆå®¶æ¨è–¦ã€+ã€ŒXæ²»ç™‚ã€ã€ã€Œè‡¨åºŠè­‰å¯¦ã€+ã€Œç™‚æ•ˆé¡¯è‘—ã€ã€ã€Œå°ˆæ¥­XXã€+ã€Œæ¨è–¦ç”¢å“åã€ã€ã€Œé€šéã€+ã€ŒXæ¸¬è©¦ã€ã€ã€Œå°ˆæ¥­è—¥å¸«Xã€+ã€ŒçœŸå¿ƒæ¨è–¦Xã€ã€      ã€Œé˜»éš”ã€+ã€Œæˆåˆ†ã€ç­‰ã€‚
   - å¦‚æœä¸Šä¸‹æ–‡çš„é•è¦çµ„åˆæ¶‰åŠé†«ç™‚ã€æ²»ç™‚æ•ˆæœï¼Œæˆ–æ˜¯ä»¥æŸäººæ¨è–¦ã€æŸå¯¦é©—çµæœè­‰æ˜ä¾†å®£å‚³å•†å“ï¼Œéƒ½è¦æé«˜æœ€çµ‚åˆ¤æ–·çš„é•æ³•æ©Ÿç‡ã€‚
   - è«‹èªªæ˜é•è¦èªå¥å…§å®¹ã€‚
5. **ç¢ºèªæ˜¯å¦æœ‰å®˜æ–¹èªè­‰ï¼ˆå¦‚ï¼šè¡›ç½²å­—è™Ÿï¼‰ï¼Ÿ**
   - æœ‰å‰‡èª¿é™é¢¨éšªç­‰ç´šã€‚
6. **æ•´åˆæ™ºèƒ½æª¢æ¸¬è³‡è¨Š**:
   - æ™ºèƒ½é¢¨éšªç­‰ç´šï¼š{risk_level}
   - æ™ºèƒ½é¢¨éšªåˆ†æ•¸ï¼š{risk_score}%
   - æœ‰å…è¨±ç”¨è©ï¼š{allowed_phrases}
   - æœ‰å®˜æ–¹èªè­‰ (å¦‚è¡›ç½²å­—è™Ÿ)ï¼š{has_approval}
   - é•è¦è©æ˜¯å¦å‡ºç¾åœ¨å•†å“å…§å®¹æè¿°ä¸­ï¼Ÿé‚„æ˜¯é é¢åˆ†é¡ï¼æ¨™ç±¤ï¼Ÿ
      - è‹¥ç‚ºé é¢åˆ†é¡ã€å°èˆªæ¨™é¡Œï¼Œè«‹åˆç†èª¿é™é¢¨éšª
      - è‹¥ç‚ºå•†å“åŠŸèƒ½èªªæ˜ã€æ¨™é¡Œå®£ç¨±ï¼Œå‰‡éœ€ä¿ç•™æˆ–æå‡é¢¨éšª
   - å…è¨±ç”¨è©æ˜¯å¦çœŸæ­£å‡ºç¾åœ¨ç”¢å“æè¿°ä¸­ï¼Ÿé‚„æ˜¯åƒ…ç‚ºç‡Ÿé¤Šæˆåˆ†æ•˜è¿°ï¼Ÿ
      - è‹¥åƒ…ä½œç‚ºé…æ–™æˆ–æˆåˆ†å‡ºç¾ï¼Œè€Œç„¡å®£ç¨±ä½œç”¨ï¼Œå‰‡é¢¨éšªä¸æ‡‰éåº¦ä¸‹èª¿
7. **æ ¹æ“šä»¥ä¸Šçµæœï¼Œåˆ¤æ–·é•æ³•æ©Ÿç‡ï¼ˆå¾ä»¥ä¸‹æ•¸å€¼ä¸­é¸æ“‡ï¼‰**
   - é•æ³•æ©Ÿç‡æ‡‰ä»¥ç¬¬ 1~6 æ­¥çš„æ•´é«”èªå¢ƒã€é•æ³•è©æ˜¯å¦å‡ºç¾ã€å…è¨±ç”¨è©æ˜¯å¦å‡ºç¾ã€æ™ºèƒ½æª¢æ¸¬åˆ†æ•¸èˆ‡æ³•è¦æ¯”å°çµæœç‚ºæº–ã€‚
   - æ™ºèƒ½æª¢æ¸¬é¢¨éšªåˆ†æ•¸åƒ…ä½œç‚ºåƒè€ƒï¼Œè‹¥ç¶“èªå¢ƒåˆ†æå¾Œç™¼ç¾åˆ¤æ–·éœ€èª¿æ•´ï¼Œè«‹åˆç†èª¿é«˜æˆ–é™ä½é•æ³•æ©Ÿç‡ã€‚
   - è‹¥å»£å‘Šè©éæ–¼èª‡å¤§ï¼Œå„˜ç®¡å‡ºç¾å…è¨±ç”¨è©ï¼Œè«‹åˆç†èª¿é«˜é•æ³•æ©Ÿç‡ã€‚
   - è«‹ç¢ºä¿æœ€çµ‚é•æ³•æ©Ÿç‡èˆ‡æ•´é«”èªç¾©åˆ¤æ–·ä¸€è‡´ï¼Œé¿å…ä¸åˆé‚è¼¯çš„çŸ›ç›¾æƒ…æ³ï¼ˆä¾‹å¦‚ï¼šæ²’æœ‰é•è¦è©å»åˆ¤ç‚ºé«˜é¢¨éšªï¼‰ã€‚
   - åƒ…èƒ½é¸: 10%ã€30%ã€50%ã€70%ã€90%

---

## å›æ‡‰æ ¼å¼ï¼ˆå›æ‡‰å¿…é ˆç¬¦åˆä¸‹åˆ—ä¸‰é¸ä¸€çµæ§‹ï¼‰

### ä½é¢¨éšª (é•æ³•æ©Ÿç‡ 10% æˆ– 30%)
é•æ³•æ©Ÿç‡: 30%
âœ” å‡ºç¾å…è¨±ç”¨è©: æ˜¯ï¼ˆä¾‹å¦‚ï¼šå¹«åŠ©å…¥ç¡ã€å¥åº·ç¶­æŒï¼‰
âœ” å‡ºç¾é•è¦ç”¨è©: å¦
âœ” å‡ºç¾ä¸Šä¸‹æ–‡é•è¦çµ„åˆ: å¦
é•æ³•å…§å®¹åˆ†æ: å»£å‘Šä¸­ä½¿ç”¨åˆè¦è©å¥ï¼Œä¸”ç„¡æ˜é¡¯ç™‚æ•ˆå®£ç¨±ã€‚æ ¹æ“šæ™ºèƒ½æª¢æ¸¬é¡¯ç¤ºä½é¢¨éšªï¼Œç¶œåˆåˆ¤å®šé•æ³•å¯èƒ½æ€§ä½ã€‚
ç½°æ¬¾é¡åº¦: ç„¡
åƒè€ƒä¾æ“š: [vector store æ–‡ä»¶ ID]

### ä¸­é¢¨éšªï¼ˆé•æ³•æ©Ÿç‡ 50%ï¼‰
é•æ³•æ©Ÿç‡: 50%
âœ” å‡ºç¾å…è¨±ç”¨è©: å¦
âœ” å‡ºç¾é•è¦ç”¨è©: æ˜¯ï¼ˆä¾‹å¦‚ï¼šæ ¹æ²»ï¼‰
âœ” å‡ºç¾ä¸Šä¸‹æ–‡é•è¦çµ„åˆ: å¦
é•æ³•å…§å®¹åˆ†æ: å»£å‘Šä¸­ã€Œ[å¯¦éš›å­˜åœ¨çš„å…·é«”æ–‡å­—]ã€å¯èƒ½æ¶‰åŠç™‚æ•ˆæš—ç¤ºï¼Œå»ºè­°è¬¹æ…ä½¿ç”¨ã€‚
é•åæ¢æ¬¾: [é©ç”¨æ³•è¦]
ç½°æ¬¾é¡åº¦: [ä¾æ“šæ³•è¦]
åƒè€ƒä¾æ“š: [vector store æ–‡ä»¶ ID]

### é«˜é¢¨éšªï¼ˆé•æ³•æ©Ÿç‡ 70% æˆ– 90%ï¼‰
é•æ³•æ©Ÿç‡: 90%
âœ” å‡ºç¾å…è¨±ç”¨è©: å¦
âœ” å‡ºç¾é•è¦ç”¨è©: æ˜¯ï¼ˆæ²»ç™‚ã€ç™Œç—‡ï¼‰
âœ” å‡ºç¾ä¸Šä¸‹æ–‡é•è¦çµ„åˆ: æ˜¯ï¼ˆè‡¨åºŠè­‰å¯¦+ç™‚æ•ˆï¼‰
é•æ³•å…§å®¹åˆ†æ: å»£å‘Šä¸­ã€Œ[å¯¦éš›å­˜åœ¨çš„å…·é«”æ–‡å­—]ã€æ˜ç¢ºå®£ç¨±ç™‚æ•ˆï¼Œé•åç›¸é—œè¦å®šã€‚
é•åæ¢æ¬¾: [é©ç”¨æ³•è¦]
ç½°æ¬¾é¡åº¦: [ä¾æ“šæ³•è¦]
åƒè€ƒä¾æ“š: [vector store æ–‡ä»¶ ID]
"""
    
    # çµ„åˆç›¸é—œæ³•è¦æ–‡æœ¬å’Œvector storeä¿¡æ¯
    docs_parts = []
    for i, c in enumerate(contexts):
        source_info = f"[æ–‡ä»¶ID: {vector_store_ids[i]}]"
        docs_parts.append(f"{source_info}\n{c['text'][:500]}")
    
    docs = "\n---\n".join(docs_parts)
    
    # è¨­å®šç”¨æˆ¶æç¤º
    user_prompt = f"""## Vector Store æ³•è¦è³‡æ–™ï¼š
{docs}

## Vector Store æ–‡ä»¶ ID åˆ—è¡¨: 
{', '.join(vector_store_ids)}

## å¾…æª¢æ¸¬å»£å‘Šæ–‡æœ¬ï¼š
```
{ad_text}
```

## æ™ºèƒ½æª¢æ¸¬è©³ç´°çµæœï¼š
- åš´æ ¼é•è¦é—œéµè©: {compliance_check['strict_violations']}
- ä¸Šä¸‹æ–‡é•è¦: {compliance_check['context_violations']}
- é†«ç™‚æ›¿ä»£é•è¦: {compliance_check['substitute_violations']}
- ç™¼ç¾å…è¨±ç”¨è©: {compliance_check['allowed_phrases_found']}
- æœ‰å®˜æ–¹èªè­‰: {compliance_check['has_official_approval']}
- é¢¨éšªåˆ†æ•¸: {compliance_check['risk_score']}%
- é¢¨éšªç­‰ç´š: {compliance_check['risk_level']}

## åˆ†æè¦æ±‚ï¼š
1. **è«‹å„ªå…ˆæ ¹æ“šå»£å‘Šæ–‡æœ¬çš„å¯¦éš›èªç¾©èˆ‡ä¸Šä¸‹æ–‡é€²è¡Œåˆ¤æ–·**
2. **åªèƒ½åˆ†æå»£å‘Šä¸­å¯¦éš›å‡ºç¾çš„å…§å®¹ï¼Œä¸å¾—æ¨æ¸¬æˆ–è™›æ§‹**
3. **ç•¶ç™¼ç¾å…è¨±ç”¨è©ï¼Œæ‡‰å¾å¯¬èªå®šåˆæ³•æ€§ï¼›ä½†ä¹Ÿéœ€ç¢ºèªæ˜¯å¦åƒ…ç‚ºæˆåˆ†åˆ—èˆ‰æˆ–ç„¡å®£ç¨±åŠŸèƒ½**
4. **è‹¥é•è¦ç”¨è©åƒ…å‡ºç¾åœ¨å•†å“åˆ†é¡ã€é é¢æ¨™é¡Œç­‰ä½ç½®ï¼Œæ‡‰è¦–æƒ…å¢ƒåˆç†é™ä½é¢¨éšªåˆ¤å®š**
5. **æ™ºèƒ½æª¢æ¸¬çµæœå¯ä½œç‚ºè¼”åŠ©åƒè€ƒï¼Œä½†ä¸æ‡‰å–ä»£èªå¢ƒåˆ¤æ–·**
6. **æœ€çµ‚é•æ³•æ©Ÿç‡æ‡‰åŸºæ–¼ç¶œåˆèªå¢ƒã€æ–‡å­—å…§å®¹ã€åˆè¦ç”¨è©ã€é•è¦èªå½™èˆ‡å®˜æ–¹èªè­‰ä¾†åˆç†è©•ä¼°**

è«‹æ ¹æ“šä»¥ä¸Šè³‡æ–™èˆ‡èªå¢ƒåˆ†æçµæœé€²è¡Œåˆç†åˆ¤æ–·ï¼Œæ™ºèƒ½æª¢æ¸¬å¯ä½œç‚ºåƒè€ƒè¼”åŠ©ï¼Œä½†é•æ³•æ©Ÿç‡é ˆèˆ‡å¯¦éš›æ–‡å­—èˆ‡ä¸Šä¸‹æ–‡ç›¸ç¬¦ï¼Œä¸æ‡‰åƒ…ä¾æ“šé¢¨éšªåˆ†æ•¸æ©Ÿæ¢°åŒ–æ±ºå®šã€‚
"""
    
    # èª¿ç”¨ GPT æ¨¡å‹
    try:
        resp = openai.ChatCompletion.create(
            model="gpt-4.1-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,
            max_tokens=2000
        )
        
        analysis_result = resp.choices[0].message.content.strip()
        
        # è§£æçµæœä¸¦çµæ§‹åŒ–è¿”å›
        result = {
            'analysis': analysis_result,
            'compliance_check': compliance_check,
            'vector_store_contexts': contexts,
            'vector_store_ids': vector_store_ids,
            'processed_text': ad_text,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        return result
        
    except Exception as e:
        print(f"GPT åˆ†æå¤±æ•—: {e}")
        return {
            'error': f"åˆ†æéç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}",
            'compliance_check': compliance_check,
            'processed_text': ad_text,
            'timestamp': datetime.utcnow().isoformat()
        }

# ========= 7. å‘½ä»¤è¡Œç•Œé¢ =========

def main():
    parser = argparse.ArgumentParser(description="å¢å¼·ç‰ˆå»£å‘Šæª¢æ¸¬ç³»çµ±ï¼ˆæ”¯æ´ ColPali åœ–ç‰‡è¼¸å…¥ï¼‰")
    parser.add_argument("--rebuild", action="store_true", help="é‡å»ºå‘é‡ç´¢å¼•")
    parser.add_argument("--json_folder", default="legal_data", help="æ³•è¦ JSON è³‡æ–™å¤¾è·¯å¾‘")
    parser.add_argument("--text", help="è¦æª¢æ¸¬çš„å»£å‘Šæ–‡å­—")
    parser.add_argument("--image", help="è¦æª¢æ¸¬çš„å»£å‘Šåœ–ç‰‡è·¯å¾‘")
    parser.add_argument("--batch", help="æ‰¹é‡è™•ç†çš„ CSV æª”æ¡ˆè·¯å¾‘")
    parser.add_argument("--output", help="çµæœè¼¸å‡ºæª”æ¡ˆè·¯å¾‘")
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–å‘é‡è³‡æ–™åº«
    print("ğŸ”§ åˆå§‹åŒ–å‘é‡è³‡æ–™åº«...")
    vs = EnhancedVectorStore()
    
    if args.rebuild:
        print("ğŸ”„ é‡å»ºå‘é‡ç´¢å¼•...")
        vs.build(args.json_folder)
        print("âœ… ç´¢å¼•é‡å»ºå®Œæˆï¼")
        return
    else:
        try:
            vs.load()
        except FileNotFoundError:
            print("âš ï¸  æ‰¾ä¸åˆ°ç¾æœ‰ç´¢å¼•ï¼Œè‡ªå‹•å»ºç«‹æ–°ç´¢å¼•...")
            vs.build(args.json_folder)
    
    # åˆå§‹åŒ–å¢å¼·ç‰ˆæª¢æ¸¬å™¨
    print("ğŸš€ åˆå§‹åŒ–å»£å‘Šæª¢æ¸¬å™¨...")
    detector = EnhancedAdvertisementDetector(vs)
    
    # è™•ç†ä¸åŒé¡å‹çš„è¼¸å…¥
    results = []
    
    if args.text:
        print("ğŸ“ è™•ç†æ–‡å­—è¼¸å…¥...")
        result = detector.detect_advertisement_compliance(args.text, "text")
        results.append({
            'input': args.text,
            'type': 'text',
            'result': result
        })
        print("\n" + "="*60)
        print("ğŸ“Š æª¢æ¸¬çµæœ")
        print("="*60)
        if 'analysis' in result:
            print(result['analysis'])
        else:
            print(f"âŒ éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    elif args.image:
        print("ğŸ–¼ï¸  è™•ç†åœ–ç‰‡è¼¸å…¥...")
        result = detector.detect_advertisement_compliance(args.image, "image")
        results.append({
            'input': args.image,
            'type': 'image',
            'result': result
        })
        print("\n" + "="*60)
        print("ğŸ“Š æª¢æ¸¬çµæœ")
        print("="*60)
        if 'analysis' in result:
            print(f"ğŸ“· åœ–ç‰‡è·¯å¾‘: {args.image}")
            if 'extracted_text' in result:
                print(f"ğŸ“ æå–æ–‡å­—: {result['extracted_text'][:200]}...")
            print(result['analysis'])
        else:
            print(f"âŒ éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
    
    elif args.batch:
        print("ğŸ“¦ è™•ç†æ‰¹é‡è¼¸å…¥...")
        try:
            import pandas as pd
            df = pd.read_csv(args.batch)
            
            for idx, row in df.iterrows():
                print(f"ğŸ”„ è™•ç†ç¬¬ {idx+1} ç­†è³‡æ–™...")
                
                # æª¢æŸ¥æ˜¯å¦æœ‰åœ–ç‰‡è·¯å¾‘æ¬„ä½
                if 'image_path' in row and pd.notna(row['image_path']):
                    result = detector.detect_advertisement_compliance(row['image_path'], "image")
                    input_data = row['image_path']
                    input_type = 'image'
                elif 'text' in row and pd.notna(row['text']):
                    result = detector.detect_advertisement_compliance(row['text'], "text")
                    input_data = row['text']
                    input_type = 'text'
                else:
                    print(f"âš ï¸  ç¬¬ {idx+1} ç­†è³‡æ–™ç¼ºå°‘æœ‰æ•ˆè¼¸å…¥")
                    continue
                
                results.append({
                    'index': idx,
                    'input': input_data,
                    'type': input_type,
                    'result': result
                })
            
            print(f"âœ… æ‰¹é‡è™•ç†å®Œæˆï¼Œå…±è™•ç† {len(results)} ç­†è³‡æ–™")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡è™•ç†å¤±æ•—: {e}")
            return
    
    else:
        print("âš ï¸  è«‹æä¾›è¦æª¢æ¸¬çš„æ–‡å­—ï¼ˆ--textï¼‰æˆ–åœ–ç‰‡ï¼ˆ--imageï¼‰æˆ–æ‰¹é‡æª”æ¡ˆï¼ˆ--batchï¼‰")
        print("\nä½¿ç”¨ç¯„ä¾‹:")
        print("  æ–‡å­—æª¢æ¸¬: python script.py --text 'æœ¬ç”¢å“èƒ½æœ‰æ•ˆæ”¹å–„é«”è³ª'")
        print("  åœ–ç‰‡æª¢æ¸¬: python script.py --image 'advertisement.jpg'")
        print("  æ‰¹é‡è™•ç†: python script.py --batch 'data.csv'")
        print("  é‡å»ºç´¢å¼•: python script.py --rebuild")
        return
    
    # è¼¸å‡ºçµæœ
    if args.output:
        print(f"ğŸ’¾ å„²å­˜çµæœåˆ° {args.output}")
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
    
    print("ğŸ‰ æª¢æ¸¬å®Œæˆï¼")

# ========= 8. äº’å‹•å¼ç•Œé¢ =========

def interactive_mode():
    """äº’å‹•å¼æª¢æ¸¬æ¨¡å¼"""
    print("=" * 60)
    print("ğŸ” å¢å¼·ç‰ˆå»£å‘Šæª¢æ¸¬ç³»çµ±")
    print("æ”¯æ´æ–‡å­—å’Œåœ–ç‰‡è¼¸å…¥ï¼ˆColPali æŠ€è¡“ï¼‰")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»çµ±
    vs = EnhancedVectorStore()
    try:
        vs.load()
        print("âœ… å‘é‡è³‡æ–™åº«è¼‰å…¥æˆåŠŸ")
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ°ç´¢å¼•æª”æ¡ˆï¼Œè«‹å…ˆä½¿ç”¨ --rebuild å»ºç«‹ç´¢å¼•")
        return
    
    detector = EnhancedAdvertisementDetector(vs)
    
    while True:
        print("\n" + "="*50)
        print("è«‹é¸æ“‡è¼¸å…¥é¡å‹:")
        print("1. ğŸ“ æ–‡å­—è¼¸å…¥")
        print("2. ğŸ–¼ï¸  åœ–ç‰‡è¼¸å…¥ (ColPali)")
        print("3. ğŸšª é€€å‡º")
        
        choice = input("è«‹è¼¸å…¥é¸é … (1-3): ").strip()
        
        if choice == "1":
            text = input("è«‹è¼¸å…¥å»£å‘Šæ–‡å­—: ").strip()
            if text:
                result = detector.detect_advertisement_compliance(text, "text")
                print("\n" + "="*60)
                print("ğŸ“Š æª¢æ¸¬çµæœ")
                print("="*60)
                if 'analysis' in result:
                    print(result['analysis'])
                else:
                    print(f"âŒ éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
            else:
                print("âš ï¸  è«‹è¼¸å…¥æœ‰æ•ˆçš„æ–‡å­—å…§å®¹")
        
        elif choice == "2":
            image_path = input("è«‹è¼¸å…¥åœ–ç‰‡è·¯å¾‘: ").strip()
            if image_path and os.path.exists(image_path):
                result = detector.detect_advertisement_compliance(image_path, "image")
                print("\n" + "="*60)
                print("ğŸ“Š æª¢æ¸¬çµæœ")
                print("="*60)
                if 'analysis' in result:
                    if 'extracted_text' in result:
                        print(f"ğŸ“ æå–æ–‡å­—: {result['extracted_text'][:200]}...")
                    print(result['analysis'])
                else:
                    print(f"âŒ éŒ¯èª¤: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
            else:
                print("âŒ åœ–ç‰‡æª”æ¡ˆä¸å­˜åœ¨æˆ–è·¯å¾‘ç„¡æ•ˆ")
        
        elif choice == "3":
            print("ğŸ‘‹ æ„Ÿè¬ä½¿ç”¨å»£å‘Šæª¢æ¸¬ç³»çµ±ï¼")
            break
        
        else:
            print("âŒ ç„¡æ•ˆé¸é …ï¼Œè«‹é‡æ–°é¸æ“‡")

# ========= 9. ä½¿ç”¨ç¯„ä¾‹ =========

def example_usage():
    """ä½¿ç”¨ç¯„ä¾‹"""
    print("=" * 60)
    print("ğŸ“š ä½¿ç”¨ç¯„ä¾‹")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»çµ±
    vs = EnhancedVectorStore()
    try:
        vs.load()  # å‡è¨­å·²æœ‰ç´¢å¼•
    except FileNotFoundError:
        print("âŒ è«‹å…ˆå»ºç«‹ç´¢å¼•: python script.py --rebuild")
        return
    
    detector = EnhancedAdvertisementDetector(vs)
    
    # æ–‡å­—æª¢æ¸¬ç¯„ä¾‹
    print("ğŸ“ æ–‡å­—æª¢æ¸¬ç¯„ä¾‹:")
    text_example = "æœ¬ç”¢å“èƒ½æœ‰æ•ˆæ²»ç™‚ç³–å°¿ç—…ï¼Œç¶“è‡¨åºŠè­‰å¯¦ç™‚æ•ˆé¡¯è‘—ï¼"
    result = detector.detect_advertisement_compliance(text_example, "text")
    print("æª¢æ¸¬çµæœ:")
    print(result.get('analysis', 'æª¢æ¸¬å¤±æ•—'))
    
    # åœ–ç‰‡æª¢æ¸¬ç¯„ä¾‹ï¼ˆå‡è¨­æœ‰åœ–ç‰‡ï¼‰
    print("\nğŸ–¼ï¸  åœ–ç‰‡æª¢æ¸¬ç¯„ä¾‹:")
    image_example = "advertisement.jpg"
    if os.path.exists(image_example):
        result = detector.detect_advertisement_compliance(image_example, "image")
        print("æª¢æ¸¬çµæœ:")
        print(result.get('analysis', 'æª¢æ¸¬å¤±æ•—'))
    else:
        print("âŒ ç¯„ä¾‹åœ–ç‰‡ä¸å­˜åœ¨")

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) == 1:
        # æ²’æœ‰åƒæ•¸æ™‚å•Ÿå‹•äº’å‹•æ¨¡å¼
        interactive_mode()
    else:
        # æœ‰åƒæ•¸æ™‚ä½¿ç”¨å‘½ä»¤è¡Œæ¨¡å¼
        main()
